{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc62158e-d44a-4821-ad53-8cfbac025a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bioimage\n",
    "\n",
    "from interactive_m2unet import M2UnetInteractiveModel\n",
    "import numpy as np\n",
    "import imageio\n",
    "import albumentations as A\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label\n",
    "# Uncomment to specify the gpu number\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "TRAIN = True\n",
    "TEST = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6e47621-7cc7-4e3d-8e3a-7d3e87772581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n",
      "./cell_data_3/train/0_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "epoch: \n",
      "0\n",
      "iteration: 1, loss: 2.356454849243164\n",
      "iteration: 2, loss: 1.4827015399932861\n",
      "iteration: 3, loss: 2.014787197113037\n",
      "iteration: 4, loss: 1.3171403408050537\n",
      "iteration: 5, loss: 0.9444992542266846\n",
      "iteration: 6, loss: 0.9421392679214478\n",
      "iteration: 7, loss: 0.6598946452140808\n",
      "iteration: 8, loss: 0.6052147150039673\n",
      "iteration: 9, loss: 1.027336835861206\n",
      "iteration: 10, loss: 1.0090519189834595\n",
      "iteration: 11, loss: 0.7985918521881104\n",
      "iteration: 12, loss: 0.6746089458465576\n",
      "iteration: 13, loss: 0.7757223844528198\n",
      "iteration: 14, loss: 0.6755494475364685\n",
      "iteration: 15, loss: 0.8756182193756104\n",
      "iteration: 16, loss: 0.673263430595398\n",
      "iteration: 17, loss: 0.877530574798584\n",
      "iteration: 18, loss: 0.5456797480583191\n",
      "iteration: 19, loss: 0.5811808109283447\n",
      "iteration: 20, loss: 0.6027785539627075\n",
      "iteration: 21, loss: 0.627946138381958\n",
      "iteration: 22, loss: 0.4938548505306244\n",
      "iteration: 23, loss: 0.6012077331542969\n",
      "iteration: 24, loss: 0.5081626176834106\n",
      "iteration: 25, loss: 0.8215793371200562\n",
      "iteration: 26, loss: 0.9515542984008789\n",
      "iteration: 27, loss: 0.5123403072357178\n",
      "iteration: 28, loss: 0.47437775135040283\n",
      "iteration: 29, loss: 0.482001930475235\n",
      "iteration: 30, loss: 0.40893852710723877\n",
      "iteration: 31, loss: 0.4573479890823364\n",
      "iteration: 32, loss: 0.3948310613632202\n",
      "iteration: 33, loss: 0.3765231668949127\n",
      "iteration: 34, loss: 0.8486345410346985\n",
      "iteration: 35, loss: 0.7969213724136353\n",
      "iteration: 36, loss: 0.40813374519348145\n",
      "iteration: 37, loss: 0.4489843249320984\n",
      "iteration: 38, loss: 0.48039984703063965\n",
      "iteration: 39, loss: 0.5842272043228149\n",
      "iteration: 40, loss: 0.5836138129234314\n",
      "iteration: 41, loss: 0.39753419160842896\n",
      "iteration: 42, loss: 0.5874346494674683\n",
      "iteration: 43, loss: 0.45552176237106323\n",
      "iteration: 44, loss: 0.3881945013999939\n",
      "iteration: 45, loss: 0.38491982221603394\n",
      "iteration: 46, loss: 0.429157555103302\n",
      "iteration: 47, loss: 0.3702147305011749\n",
      "iteration: 48, loss: 0.4066673219203949\n",
      "iteration: 49, loss: 0.37153181433677673\n",
      "iteration: 50, loss: 0.37596720457077026\n",
      "iteration: 51, loss: 0.3533583879470825\n",
      "iteration: 52, loss: 0.35557079315185547\n",
      "iteration: 53, loss: 0.3978778123855591\n",
      "iteration: 54, loss: 0.3424586057662964\n",
      "iteration: 55, loss: 0.3245971202850342\n",
      "iteration: 56, loss: 0.2906245291233063\n",
      "iteration: 57, loss: 0.28580549359321594\n",
      "iteration: 58, loss: 0.2654985785484314\n",
      "iteration: 59, loss: 0.3390987813472748\n",
      "iteration: 60, loss: 0.8042937517166138\n",
      "iteration: 61, loss: 0.31226617097854614\n",
      "iteration: 62, loss: 0.303974986076355\n",
      "iteration: 63, loss: 0.30646878480911255\n",
      "iteration: 64, loss: 0.42412230372428894\n",
      "iteration: 65, loss: 0.2801293730735779\n",
      "iteration: 66, loss: 0.2990031838417053\n",
      "iteration: 67, loss: 0.3026968538761139\n",
      "iteration: 68, loss: 0.315232515335083\n",
      "iteration: 69, loss: 0.7628659009933472\n",
      "iteration: 70, loss: 0.7257289886474609\n",
      "iteration: 71, loss: 0.24929766356945038\n",
      "iteration: 72, loss: 0.32199761271476746\n",
      "iteration: 73, loss: 0.2878692150115967\n",
      "iteration: 74, loss: 0.420160174369812\n",
      "iteration: 75, loss: 0.2953610420227051\n",
      "iteration: 76, loss: 0.32444483041763306\n",
      "iteration: 77, loss: 0.26415014266967773\n",
      "iteration: 78, loss: 0.24477088451385498\n",
      "iteration: 79, loss: 0.26537850499153137\n",
      "iteration: 80, loss: 0.6584371328353882\n",
      "epoch: \n",
      "1\n",
      "iteration: 81, loss: 0.5948121547698975\n",
      "iteration: 82, loss: 0.28199613094329834\n",
      "iteration: 83, loss: 0.26534491777420044\n",
      "iteration: 84, loss: 0.2891361713409424\n",
      "iteration: 85, loss: 0.26572322845458984\n",
      "iteration: 86, loss: 0.2616068124771118\n",
      "iteration: 87, loss: 0.3665282130241394\n",
      "iteration: 88, loss: 0.2629644274711609\n",
      "iteration: 89, loss: 0.24112264811992645\n",
      "iteration: 90, loss: 0.24134612083435059\n",
      "iteration: 91, loss: 0.23435866832733154\n",
      "iteration: 92, loss: 0.220741406083107\n",
      "iteration: 93, loss: 0.5511561632156372\n",
      "iteration: 94, loss: 0.20569095015525818\n",
      "iteration: 95, loss: 0.21203750371932983\n",
      "iteration: 96, loss: 0.24870584905147552\n",
      "iteration: 97, loss: 0.5088716745376587\n",
      "iteration: 98, loss: 0.21202528476715088\n",
      "iteration: 99, loss: 0.22195452451705933\n",
      "iteration: 100, loss: 0.1988009810447693\n",
      "iteration: 101, loss: 0.22071793675422668\n",
      "iteration: 102, loss: 0.19931194186210632\n",
      "iteration: 103, loss: 0.22033557295799255\n",
      "iteration: 104, loss: 0.21222993731498718\n",
      "iteration: 105, loss: 0.2184506207704544\n",
      "iteration: 106, loss: 0.18263566493988037\n",
      "iteration: 107, loss: 0.15976350009441376\n",
      "iteration: 108, loss: 0.17230191826820374\n",
      "iteration: 109, loss: 1.373706340789795\n",
      "iteration: 110, loss: 0.46492788195610046\n",
      "iteration: 111, loss: 0.41593268513679504\n",
      "iteration: 112, loss: 0.29540473222732544\n",
      "iteration: 113, loss: 0.2998252511024475\n",
      "iteration: 114, loss: 0.3479383885860443\n",
      "iteration: 115, loss: 0.41727763414382935\n",
      "iteration: 116, loss: 0.3572891354560852\n",
      "iteration: 117, loss: 0.3742629289627075\n",
      "iteration: 118, loss: 0.5055283308029175\n",
      "iteration: 119, loss: 0.3922715485095978\n",
      "iteration: 120, loss: 0.3601216971874237\n",
      "iteration: 121, loss: 0.34591901302337646\n",
      "iteration: 122, loss: 0.3729005455970764\n",
      "iteration: 123, loss: 0.3139500319957733\n",
      "iteration: 124, loss: 0.28555214405059814\n",
      "iteration: 125, loss: 0.25105106830596924\n",
      "iteration: 126, loss: 0.34016063809394836\n",
      "iteration: 127, loss: 0.24466943740844727\n",
      "iteration: 128, loss: 0.271054208278656\n",
      "iteration: 129, loss: 0.21752262115478516\n",
      "iteration: 130, loss: 0.33257827162742615\n",
      "iteration: 131, loss: 0.1956719160079956\n",
      "iteration: 132, loss: 0.2343006432056427\n",
      "iteration: 133, loss: 0.30110400915145874\n",
      "iteration: 134, loss: 0.20323294401168823\n",
      "iteration: 135, loss: 0.19908638298511505\n",
      "iteration: 136, loss: 0.18701928853988647\n",
      "iteration: 137, loss: 0.22247186303138733\n",
      "iteration: 138, loss: 0.2661105990409851\n",
      "iteration: 139, loss: 0.4159698188304901\n",
      "iteration: 140, loss: 0.18336591124534607\n",
      "iteration: 141, loss: 0.1856893002986908\n",
      "iteration: 142, loss: 0.30000656843185425\n",
      "iteration: 143, loss: 0.1967088282108307\n",
      "iteration: 144, loss: 0.30925261974334717\n",
      "iteration: 145, loss: 0.1859111487865448\n",
      "iteration: 146, loss: 0.25489717721939087\n",
      "iteration: 147, loss: 0.1971043050289154\n",
      "iteration: 148, loss: 0.2611271142959595\n",
      "iteration: 149, loss: 0.20386254787445068\n",
      "iteration: 150, loss: 0.1977507323026657\n",
      "iteration: 151, loss: 0.16753248870372772\n",
      "iteration: 152, loss: 0.2050941288471222\n",
      "iteration: 153, loss: 0.17137029767036438\n",
      "iteration: 154, loss: 0.326609343290329\n",
      "iteration: 155, loss: 0.1504720151424408\n",
      "iteration: 156, loss: 0.20244982838630676\n",
      "iteration: 157, loss: 0.1794617474079132\n",
      "iteration: 158, loss: 0.14856089651584625\n",
      "iteration: 159, loss: 0.1488160789012909\n",
      "iteration: 160, loss: 0.18283648788928986\n"
     ]
    }
   ],
   "source": [
    "# a function for loading cellpose output (image, mask and outline)\n",
    "def load_samples(train_dir):\n",
    "    npy_files = [os.path.join(train_dir, s) for s in os.listdir(train_dir) if s.endswith('.npy')]\n",
    "    samples = []\n",
    "    for file in npy_files:\n",
    "        print(file)\n",
    "        try:\n",
    "            items = np.load(file, allow_pickle=True).item()\n",
    "        except:\n",
    "            print(\"Bad Item\")\n",
    "            continue\n",
    "        mask = (items['masks'][:, :, None]  > 0) * 1.0\n",
    "        outline = (items['outlines'][:, :, None]  > 0) * 1.0\n",
    "        mask = mask * (1.0 - outline)\n",
    "        sample = (items['img'], mask)\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "# check if GPU is available\n",
    "print(f'GPU: {torch.cuda.is_available()}')\n",
    "\n",
    "# setting up\n",
    "data_dir = './cell_data_3' # data should contain a train and a test folder\n",
    "model_root = \"./models_100\"\n",
    "epochs = 2\n",
    "steps = 1\n",
    "resume = True\n",
    "corrid = \"200\"\n",
    "pretrained_model = None  # os.path.join(model_root, str(corrid), \"model.h5\")\n",
    "os.makedirs(os.path.join(model_root, str(corrid)), exist_ok=True)\n",
    "sz = 2048\n",
    "sz_outer = int(sz* 1.5)\n",
    "\n",
    "# define the transforms\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(sz, sz),\n",
    "        #A.Rotate(limit=[-5, 5], p=1),\n",
    "        A.Flip(p=0.5),\n",
    "        #A.CenterCrop(sz, sz),\n",
    "    ]\n",
    ")\n",
    "A.save(transform, \"./models/transform.json\")\n",
    "# unet model hyperparamer can be found here: https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=f899f7a8a9144b3f946c4a1362f7e38ae0c00c59&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f79696e676b61697368612f6b657261732d756e65742d636f6c6c656374696f6e2f663839396637613861393134346233663934366334613133363266376533386165306330306335392f6578616d706c65732f757365725f67756964655f6d6f64656c732e6970796e62&logged_in=true&nwo=yingkaisha%2Fkeras-unet-collection&path=examples%2Fuser_guide_models.ipynb&platform=mac&repository_id=323426984&repository_type=Repository&version=95#Swin-UNET\n",
    "model_config = {\n",
    "    \"type\": \"m2unet\",\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"output_channels\": 1,\n",
    "    \"loss\": {\"name\": \"BCELoss\", \"kwargs\": {}},\n",
    "    \"optimizer\": {\"name\": \"RMSprop\", \"kwargs\": {\"lr\": 1e-2, \"weight_decay\": 1e-8, \"momentum\": 0.9}},\n",
    "    \"augmentation\": A.to_dict(transform),\n",
    "}\n",
    "model = M2UnetInteractiveModel(\n",
    "    model_config=model_config,\n",
    "    model_dir=model_root,\n",
    "    resume=resume,\n",
    "    pretrained_model=pretrained_model,\n",
    "    default_save_path=os.path.join(model_root, str(corrid), \"model.pth\"),\n",
    ")\n",
    "\n",
    "# load samples\n",
    "train_samples = load_samples(data_dir + '/train')\n",
    "test_samples = load_samples(data_dir + '/test')\n",
    "\n",
    "# train the model \n",
    "if TRAIN:\n",
    "    iterations = 0\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch: ')\n",
    "        print(epoch)\n",
    "        losses = []\n",
    "        # image shape: sz, sz, 3\n",
    "        # labels shape: sz, sz, 1\n",
    "        for (image, labels) in train_samples:\n",
    "            mask = model.transform_labels(labels)\n",
    "            x = np.expand_dims(image, axis=0)\n",
    "            y = np.expand_dims(mask, axis=0)\n",
    "            losses = []\n",
    "            for _ in range(steps):\n",
    "                # x and y will be augmented for each step\n",
    "                loss = model.train_on_batch(x, y)\n",
    "                losses.append(loss)\n",
    "                iterations += 1\n",
    "                print(f\"iteration: {iterations}, loss: {loss}\")\n",
    "    model.save()\n",
    "\n",
    "# test\n",
    "if TEST:\n",
    "    for i, sample in enumerate(test_samples):\n",
    "        inputs = sample[0].astype(\"float32\")[None, :sz, :sz, :]\n",
    "        imageio.imwrite(f\"octopi-inputs_{i}.png\", inputs[0].astype('uint8'))\n",
    "        labels = sample[1].astype(\"float32\")[None, :sz, :sz, :] * 255\n",
    "        imageio.imwrite(f\"octopi-labels_{i}.png\", labels[0].astype('uint8'))\n",
    "        results = model.predict(inputs)\n",
    "        output = np.clip(results[0] * 255, 0, 255)[:, :, 0].astype('uint8')\n",
    "        imageio.imwrite(f\"octopi-pred-prob_{i}.png\", output)\n",
    "        threshold = threshold_otsu(output)\n",
    "        mask = ((output > threshold) * 255).astype('uint8')\n",
    "        predict_labels = label(mask)\n",
    "        imageio.imwrite(f\"octopi-pred-labels_{i}.png\", predict_labels)\n",
    "\n",
    "    print(\"all done\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a529bfb-8b30-420f-b995-ae16b4b80956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n",
      "./cell_data_3/train/0_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "epoch: \n",
      "0\n",
      "iteration: 1, loss: 0.19246330857276917\n",
      "iteration: 2, loss: 0.610487699508667\n",
      "iteration: 3, loss: 0.4067736566066742\n",
      "iteration: 4, loss: 0.19329480826854706\n",
      "iteration: 5, loss: 0.6577390432357788\n",
      "iteration: 6, loss: 0.6742488741874695\n",
      "iteration: 7, loss: 0.43374013900756836\n",
      "iteration: 8, loss: 0.3835068941116333\n",
      "iteration: 9, loss: 0.7126250863075256\n",
      "iteration: 10, loss: 0.2591300308704376\n",
      "iteration: 11, loss: 0.25860336422920227\n",
      "iteration: 12, loss: 0.4634484350681305\n",
      "iteration: 13, loss: 0.46899428963661194\n",
      "iteration: 14, loss: 0.37147781252861023\n",
      "iteration: 15, loss: 0.3314878046512604\n",
      "iteration: 16, loss: 0.3745572566986084\n",
      "iteration: 17, loss: 0.2707327604293823\n",
      "iteration: 18, loss: 0.3542219400405884\n",
      "iteration: 19, loss: 0.26560473442077637\n",
      "iteration: 20, loss: 0.21047455072402954\n",
      "iteration: 21, loss: 0.2248760163784027\n",
      "iteration: 22, loss: 0.2011503428220749\n",
      "iteration: 23, loss: 0.27184373140335083\n",
      "iteration: 24, loss: 0.21341341733932495\n",
      "iteration: 25, loss: 0.22970576584339142\n",
      "iteration: 26, loss: 0.25309473276138306\n",
      "iteration: 27, loss: 0.19412536919116974\n",
      "iteration: 28, loss: 0.21670693159103394\n",
      "iteration: 29, loss: 0.22377218306064606\n",
      "iteration: 30, loss: 0.13686437904834747\n",
      "iteration: 31, loss: 0.1918492615222931\n",
      "iteration: 32, loss: 0.13546155393123627\n",
      "iteration: 33, loss: 0.15360566973686218\n",
      "iteration: 34, loss: 0.17560036480426788\n",
      "iteration: 35, loss: 0.14963433146476746\n",
      "iteration: 36, loss: 0.11958134174346924\n",
      "iteration: 37, loss: 0.2166679948568344\n",
      "iteration: 38, loss: 0.26146483421325684\n",
      "iteration: 39, loss: 0.15119989216327667\n",
      "iteration: 40, loss: 0.154445618391037\n",
      "iteration: 41, loss: 0.2542821764945984\n",
      "iteration: 42, loss: 0.24938970804214478\n",
      "iteration: 43, loss: 0.12685170769691467\n",
      "iteration: 44, loss: 0.12495677173137665\n",
      "iteration: 45, loss: 0.13125059008598328\n",
      "iteration: 46, loss: 0.2433355748653412\n",
      "iteration: 47, loss: 0.1383465826511383\n",
      "iteration: 48, loss: 0.14957065880298615\n",
      "iteration: 49, loss: 0.12216866761445999\n",
      "iteration: 50, loss: 0.11919581890106201\n",
      "iteration: 51, loss: 0.11850786209106445\n",
      "iteration: 52, loss: 0.10933244228363037\n",
      "iteration: 53, loss: 0.27341562509536743\n",
      "iteration: 54, loss: 0.17374512553215027\n",
      "iteration: 55, loss: 0.1318608522415161\n",
      "iteration: 56, loss: 0.14508956670761108\n",
      "iteration: 57, loss: 0.16267797350883484\n",
      "iteration: 58, loss: 0.12299159169197083\n",
      "iteration: 59, loss: 0.17925062775611877\n",
      "iteration: 60, loss: 0.13409534096717834\n",
      "iteration: 61, loss: 0.12810559570789337\n",
      "iteration: 62, loss: 0.12067767977714539\n",
      "iteration: 63, loss: 0.15947192907333374\n",
      "iteration: 64, loss: 0.14709365367889404\n",
      "iteration: 65, loss: 0.14004001021385193\n",
      "iteration: 66, loss: 0.14165867865085602\n",
      "iteration: 67, loss: 0.13573727011680603\n",
      "iteration: 68, loss: 0.1706165373325348\n",
      "iteration: 69, loss: 0.11559544503688812\n",
      "iteration: 70, loss: 0.11091019958257675\n",
      "iteration: 71, loss: 0.09451422095298767\n",
      "iteration: 72, loss: 0.11984333395957947\n",
      "iteration: 73, loss: 0.10755544900894165\n",
      "iteration: 74, loss: 0.19327405095100403\n",
      "iteration: 75, loss: 0.09292483329772949\n",
      "iteration: 76, loss: 0.13924185931682587\n",
      "iteration: 77, loss: 0.10030144453048706\n",
      "iteration: 78, loss: 0.12473318725824356\n",
      "iteration: 79, loss: 0.11235997825860977\n",
      "iteration: 80, loss: 0.0941658616065979\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22513/186836644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"octopi-inputs_{i}.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "TEST = True\n",
    "TRAIN = True\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import albumentations as A\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label\n",
    "# Uncomment to specify the gpu number\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# a function for loading cellpose output (image, mask and outline)\n",
    "def load_samples(train_dir):\n",
    "    npy_files = [os.path.join(train_dir, s) for s in os.listdir(train_dir) if s.endswith('.npy')]\n",
    "    samples = []\n",
    "    for file in npy_files:\n",
    "        print(file)\n",
    "        try:\n",
    "            items = np.load(file, allow_pickle=True).item()\n",
    "        except:\n",
    "            print(\"Bad Item\")\n",
    "            continue\n",
    "        mask = (items['masks'][:, :, None]  > 0) * 1.0\n",
    "        outline = (items['outlines'][:, :, None]  > 0) * 1.0\n",
    "        mask = mask * (1.0 - outline)\n",
    "        sample = (items['img'], mask)\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "# check if GPU is available\n",
    "print(f'GPU: {torch.cuda.is_available()}')\n",
    "\n",
    "# setting up\n",
    "data_dir = './cell_data_3' # data should contain a train and a test folder\n",
    "model_root = \"./models_100\"\n",
    "epochs = 1\n",
    "steps = 1\n",
    "resume = True\n",
    "corrid = \"200\"\n",
    "pretrained_model = None  # os.path.join(model_root, str(corrid), \"model.h5\")\n",
    "os.makedirs(os.path.join(model_root, str(corrid)), exist_ok=True)\n",
    "sz = 2048\n",
    "sz_outer = int(sz* 1.5)\n",
    "\n",
    "# define the transforms\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(sz, sz),\n",
    "        #A.Rotate(limit=[-5, 5], p=1),\n",
    "        A.Flip(p=0.5),\n",
    "        #A.CenterCrop(sz, sz),\n",
    "    ]\n",
    ")\n",
    "A.save(transform, \"./models/transform.json\")\n",
    "# unet model hyperparamer can be found here: https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=f899f7a8a9144b3f946c4a1362f7e38ae0c00c59&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f79696e676b61697368612f6b657261732d756e65742d636f6c6c656374696f6e2f663839396637613861393134346233663934366334613133363266376533386165306330306335392f6578616d706c65732f757365725f67756964655f6d6f64656c732e6970796e62&logged_in=true&nwo=yingkaisha%2Fkeras-unet-collection&path=examples%2Fuser_guide_models.ipynb&platform=mac&repository_id=323426984&repository_type=Repository&version=95#Swin-UNET\n",
    "model_config = {\n",
    "    \"type\": \"m2unet\",\n",
    "    \"activation\": \"sigmoid\",\n",
    "    \"output_channels\": 1,\n",
    "    \"loss\": {\"name\": \"BCELoss\", \"kwargs\": {}},\n",
    "    \"optimizer\": {\"name\": \"RMSprop\", \"kwargs\": {\"lr\": 1e-2, \"weight_decay\": 1e-8, \"momentum\": 0.9}},\n",
    "    \"augmentation\": A.to_dict(transform),\n",
    "}\n",
    "model = M2UnetInteractiveModel(\n",
    "    model_config=model_config,\n",
    "    model_dir=model_root,\n",
    "    resume=resume,\n",
    "    pretrained_model=pretrained_model,\n",
    "    default_save_path=os.path.join(model_root, str(corrid), \"model.pth\"),\n",
    ")\n",
    "\n",
    "# load samples\n",
    "train_samples = load_samples(data_dir + '/train')\n",
    "test_samples = load_samples(data_dir + '/test')\n",
    "\n",
    "# train the model \n",
    "if TRAIN:\n",
    "    iterations = 0\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch: ')\n",
    "        print(epoch)\n",
    "        losses = []\n",
    "        # image shape: sz, sz, 3\n",
    "        # labels shape: sz, sz, 1\n",
    "        for (image, labels) in train_samples:\n",
    "            mask = model.transform_labels(labels)\n",
    "            x = np.expand_dims(image, axis=0)\n",
    "            y = np.expand_dims(mask, axis=0)\n",
    "            losses = []\n",
    "            for _ in range(steps):\n",
    "                # x and y will be augmented for each step\n",
    "                loss = model.train_on_batch(x, y)\n",
    "                losses.append(loss)\n",
    "                iterations += 1\n",
    "                print(f\"iteration: {iterations}, loss: {loss}\")\n",
    "    model.save()\n",
    "\n",
    "# test\n",
    "if TEST:\n",
    "    for i, sample in enumerate(test_samples):\n",
    "        inputs = sample[0].astype(\"float32\")[None, :sz, :sz, :]\n",
    "        print[inputs[0].shape]\n",
    "        imageio.imwrite(f\"octopi-inputs_{i}.png\", inputs[0].astype('uint8'))\n",
    "        labels = sample[1].astype(\"float32\")[None, :sz, :sz, :] * 255\n",
    "        imageio.imwrite(f\"octopi-labels_{i}.png\", labels[0].astype('uint8'))\n",
    "        results = model.predict(inputs)\n",
    "        output = np.clip(results[0] * 255, 0, 255)[:, :, 0].astype('uint8')\n",
    "        imageio.imwrite(f\"octopi-pred-prob_{i}.png\", output)\n",
    "        threshold = threshold_otsu(output)\n",
    "        mask = ((output > threshold) * 255).astype('uint8')\n",
    "        predict_labels = label(mask)\n",
    "        imageio.imwrite(f\"octopi-pred-labels_{i}.png\", predict_labels)\n",
    "\n",
    "    print(\"all done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd856af-95ba-404b-9275-fa9c467f9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('./072622-D5-6_2022-07-27_17-22-25.774065/3_0_f_BF_LED_matrix_dpc_seg.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca23ce-cbc4-4604-b394-ef66fc39693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae341128-934e-4a8a-a03b-626ca74f3ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.669924259185791, 0.6443573832511902, 0.6819045543670654, 0.6344529390335083, 0.6782583594322205, 0.6359854340553284, 0.6348254084587097, 0.6979055404663086, 0.6535060405731201, 0.7098541855812073, 0.6927616000175476, 0.6919836401939392, 0.6912431120872498, 0.6589328050613403, 0.678594708442688, 0.692324161529541, 0.662678062915802, 0.6622503995895386, 0.6850878000259399, 0.7019121050834656]\n",
      "0.6344529390335083\n",
      "0.7098541855812073\n"
     ]
    }
   ],
   "source": [
    "# Jaccard Similarity\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "labels_str = \"octopi-labels_\"\n",
    "pred_str = \"octopi-pred-labels_\"\n",
    "imgs = glob.glob(\"*.png\")\n",
    "n_labels = len([i for i in imgs if labels_str in i])\n",
    "\n",
    "def jaccard_sim(img1, img2):\n",
    "    n = np.prod(img1.shape)\n",
    "    a = img1 * img2\n",
    "    b = img1 + img2 - a\n",
    "    J = a/b\n",
    "    J[np.isnan(J)] = 1\n",
    "    j = np.sum(J)/n\n",
    "\n",
    "    return j\n",
    "\n",
    "\n",
    "j = []\n",
    "for i in range(n_labels):\n",
    "    label = labels_str + str(i) + \".png\"\n",
    "    pred  = pred_str + str(i) + \".png\"\n",
    "\n",
    "    i_pred = np.array(cv2.imread(pred)[:,:,0], dtype='f')\n",
    "    i_label = np.array(cv2.imread(label)[:,:,0], dtype='f')\n",
    "\n",
    "    i_pred = i_pred/255.0\n",
    "    i_label = i_label/255.0\n",
    "\n",
    "    j.append(jaccard_sim(i_label, i_pred))\n",
    "    \n",
    "print(j)\n",
    "print(min(j))\n",
    "print(max(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030c7ac-af2b-49b4-a470-d56b427c0f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store Jaccard Similarity\n",
    "\n",
    "[0.6749610304832458, 0.6765353679656982, 0.6738048791885376, 0.6553453803062439, 0.6521809697151184, 0.6666283011436462, 0.6581857204437256, 0.6607326865196228, 0.6365719437599182, 0.6806446313858032, 0.6748928427696228, 0.6598854064941406, 0.6804280281066895, 0.6643669605255127, 0.6381222605705261, 0.6740015745162964, 0.6641574501991272, 0.6487610936164856, 0.663611650466919, 0.6803819537162781]\n",
    "0.6365719437599182\n",
    "0.6806446313858032\n",
    "\n",
    "\n",
    "[0.669924259185791, 0.6443573832511902, 0.6819045543670654, 0.6344529390335083, 0.6782583594322205, 0.6359854340553284, 0.6348254084587097, 0.6979055404663086, 0.6535060405731201, 0.7098541855812073, 0.6927616000175476, 0.6919836401939392, 0.6912431120872498, 0.6589328050613403, 0.678594708442688, 0.692324161529541, 0.662678062915802, 0.6622503995895386, 0.6850878000259399, 0.7019121050834656]\n",
    "0.6344529390335083\n",
    "0.7098541855812073"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
