{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "361889c8-2714-499a-b56b-915fa2ef5ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/bioimageio/spec/shared/_resolve_source.py:433: CacheWarning: found cached /tmp/jupyter/bioimageio_cache/https/raw.githubusercontent.com/bioimage-io/bioimage.io/main/site.config.json. Skipping download of https://raw.githubusercontent.com/bioimage-io/bioimage.io/main/site.config.json.\n",
      "  warnings.warn(f\"found cached {local_path}. Skipping download of {uri}.\", category=CacheWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/bioimageio/spec/shared/_resolve_source.py:433: CacheWarning: found cached /tmp/jupyter/bioimageio_cache/https/bioimage-io.github.io/collection-bioimage-io/collection.json. Skipping download of https://bioimage-io.github.io/collection-bioimage-io/collection.json.\n",
      "  warnings.warn(f\"found cached {local_path}. Skipping download of {uri}.\", category=CacheWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bioimage\n",
    "\n",
    "from interactive_m2unet import M2UnetInteractiveModel\n",
    "import numpy as np\n",
    "import imageio\n",
    "import albumentations as A\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label\n",
    "# Uncomment to specify the gpu number\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from glob import glob\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transform\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.utils import make_grid\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "68398e90-6b5c-4d2f-84e9-064214736b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            # depthwise separable convolution block\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            # Bottleneck with expansion layer\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    14 layers of MobileNetv2 as encoder part\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "        ]\n",
    "        # Encoder Part\n",
    "        input_channel = 32 # number of input channels to first inverted (residual) block\n",
    "        self.layers = [conv_bn(3, 32, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = c\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.layers.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.layers.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # make it nn.Sequential\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "                \n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder block: upsample and concatenate with features maps from the encoder part\n",
    "    \"\"\"\n",
    "    def __init__(self,up_in_c,x_in_c,upsamplemode='bilinear',expand_ratio=0.15):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2,mode=upsamplemode,align_corners=False) # H, W -> 2H, 2W\n",
    "        self.ir1 = InvertedResidual(up_in_c+x_in_c,(x_in_c + up_in_c) // 2,stride=1,expand_ratio=expand_ratio)\n",
    "\n",
    "    def forward(self,up_in,x_in):\n",
    "        up_out = self.upsample(up_in)\n",
    "        cat_x = torch.cat([up_out, x_in] , dim=1)\n",
    "        x = self.ir1(cat_x)\n",
    "        return x\n",
    "    \n",
    "class LastDecoderBlock(nn.Module):\n",
    "    def __init__(self,x_in_c,upsamplemode='bilinear',expand_ratio=0.15, output_channels=1, activation='linear'):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2,mode=upsamplemode,align_corners=False) # H, W -> 2H, 2W\n",
    "        self.ir1 = InvertedResidual(x_in_c,16,stride=1,expand_ratio=expand_ratio)\n",
    "        layers =  [\n",
    "            nn.Conv2d(16, output_channels, 1, 1, 0, bias=True),\n",
    "        ]\n",
    "        if activation == 'sigmoid':\n",
    "            layers.append(nn.Sigmoid())\n",
    "        elif activation == 'softmax':\n",
    "            layers.append(nn.Softmax(dim=1))\n",
    "        elif activation == 'linear' or activation is None:\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError('Activation {} not implemented'.format(activation))\n",
    "        self.conv = nn.Sequential(\n",
    "           *layers\n",
    "        )\n",
    "\n",
    "    def forward(self,up_in,x_in):\n",
    "        up_out = self.upsample(up_in)\n",
    "        cat_x = torch.cat([up_out, x_in] , dim=1)\n",
    "        x = self.ir1(cat_x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class M2UNet(nn.Module):\n",
    "        def __init__(self,encoder,upsamplemode='bilinear',output_channels=1, activation=\"linear\", expand_ratio=0.15):\n",
    "            super(M2UNet,self).__init__()\n",
    "            encoder = list(encoder.children())[0]\n",
    "            \n",
    "            # self.quant = torch.quantization.QuantStub()\n",
    "            # self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "            # Encoder\n",
    "            self.conv1 = encoder[0:2]\n",
    "            self.conv2 = encoder[2:4]\n",
    "            self.conv3 = encoder[4:7]\n",
    "            self.conv4 = encoder[7:14]\n",
    "            # Decoder\n",
    "            self.decode4 = DecoderBlock(96,32,upsamplemode,expand_ratio)\n",
    "            self.decode3 = DecoderBlock(64,24,upsamplemode,expand_ratio)\n",
    "            self.decode2 = DecoderBlock(44,16,upsamplemode,expand_ratio)\n",
    "            self.decode1 = LastDecoderBlock(33,upsamplemode,expand_ratio, output_channels=output_channels, activation=activation)\n",
    "            # initilaize weights \n",
    "            self._initialize_weights()\n",
    "\n",
    "        def _initialize_weights(self):\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                    m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                    if m.bias is not None:\n",
    "                        m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    m.weight.data.fill_(1)\n",
    "                    m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    n = m.weight.size(1)\n",
    "                    m.weight.data.normal_(0, 0.01)\n",
    "                    m.bias.data.zero_()\n",
    "            \n",
    "        def forward(self,x):\n",
    "            conv1 = self.conv1(x)\n",
    "            conv2 = self.conv2(conv1)\n",
    "            conv3 = self.conv3(conv2)\n",
    "            conv4 = self.conv4(conv3)\n",
    "            decode4 = self.decode4(conv4,conv3)\n",
    "            decode3 = self.decode3(decode4,conv2)\n",
    "            decode2 = self.decode2(decode3,conv1)\n",
    "            decode1 = self.decode1(decode2,x)\n",
    "\n",
    "            return res.to(device)\n",
    "        \n",
    "def m2unet(output_channels=1,expand_ratio=0.15, activation=\"linear\", **kwargs):\n",
    "    encoder = Encoder()\n",
    "    model = M2UNet(encoder,upsamplemode='bilinear',expand_ratio=expand_ratio, output_channels=output_channels, activation=activation)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901ff82-38dc-4014-b9f2-d9c37ca966f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05da4e7-ca5f-45a9-a461-40824cefd80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91ce59e2-9d7d-4ff9-9c87-46f96ff91990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cell_data_3/train/0_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/0_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/7_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/8_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/9_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/1_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/5_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/6_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/train/2_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_3_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_1_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_8_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_4_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_2_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_7_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_9_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_6_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_0_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/4_5_f_BF_LED_matrix_dpc_seg.npy\n",
      "./cell_data_3/test/3_3_f_BF_LED_matrix_dpc_seg.npy\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "def load_samples(train_dir, size, sub_samples):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    sz = size\n",
    "    transform = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(sz, sz),\n",
    "        #A.Rotate(limit=[-5, 5], p=1),\n",
    "        # A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        A.Flip(p=0.5),\n",
    "        #A.CenterCrop(sz, sz),\n",
    "    ])\n",
    "    \n",
    "    # data_transform = transforms.Compose([\n",
    "    #     transforms.RandomResizedCrop(sz),\n",
    "    #     transforms.ToTensor(),\n",
    "    # ])\n",
    "    \n",
    "    \n",
    "    npy_files = [os.path.join(train_dir, s) for s in os.listdir(train_dir) if s.endswith('.npy')]\n",
    "    samples = []\n",
    "    for file in npy_files:\n",
    "        print(file)\n",
    "        try:\n",
    "            items = np.load(file, allow_pickle=True).item()\n",
    "        except:\n",
    "            print(\"Bad Item\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        mask = (items['masks'][:, :, None]  > 0) * 1.0\n",
    "        outline = (items['outlines'][:, :, None]  > 0) * 1.0\n",
    "        mask = mask * (1.0 - outline)\n",
    "        # sample = (items['img'], mask)\n",
    "        # sample_transform = transform(image = items['img'])\n",
    "        # label_transform = transform(image  = mask)\n",
    "        \n",
    "        for i in range(sub_samples):\n",
    "            transformed = transform(image=items['img'], mask= mask)\n",
    "            transformed_image = transformed['image']\n",
    "            transformed_mask = transformed['mask']\n",
    "\n",
    "            transformed_image = np.swapaxes(transformed_image, 0, 2)\n",
    "            transformed_mask = np.swapaxes(transformed_mask, 0, 2)\n",
    "            \n",
    "            transformed_image = torch.tensor(transformed_image)\n",
    "            transformed_mask = torch.tensor(transformed_mask)\n",
    "\n",
    "            \n",
    "            image = transformed_image.float().to(device)\n",
    "            image = image / 256 # pushing data between 0 and 1\n",
    "            label = transformed_mask.float().to(device)\n",
    "\n",
    "            sample = (image, label)\n",
    "\n",
    "            samples.append(sample)\n",
    "    \n",
    "        \n",
    "        # sample_transform = data_transform(items['img'])\n",
    "        # label_transform = data_transform(mask)\n",
    "        \n",
    "        \n",
    "    return samples\n",
    "\n",
    "# Load data into Dataloader\n",
    "\n",
    "data_dir = './cell_data_3' # data should contain a train and a test folder\n",
    "\n",
    "size = 512\n",
    "sub_samples = 4\n",
    "\n",
    "train_samples = load_samples(data_dir + '/train', size, sub_samples)\n",
    "test_samples = load_samples(data_dir + '/test',size, sub_samples)\n",
    "\n",
    "# Load data into Dataloader\n",
    "\n",
    "# for (images, labels) in enum\n",
    "bs = 4\n",
    "train_dataloader = DataLoader(train_samples, batch_size=bs, shuffle=True)\n",
    "test_dataloader = DataLoader(test_samples, batch_size=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "78d2a58b-03c8-438e-b72c-eaa5640336b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.Size([4, 1, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1, 1, 512, 512])) that is different to the input size (torch.Size([4, 1, 512, 512])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13495/1340327882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model2 = m2unet().float().to(device)\n",
    "inp = torch.randn([1, 3, 512, 512]).to(device)\n",
    "output = model2(inp)\n",
    "print(output.shape)\n",
    "target = torch.randn([1, 1, 512, 512]).to(device)\n",
    "\n",
    "criterion = nn.MSELoss().cuda('0')\n",
    "\n",
    "loss = criterion(output,target)\n",
    "\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "be087c7a-acd8-462b-8fea-d919a9b57c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "tensor(28.5480, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13495/2209277122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = m2unet().float().to(device)\n",
    "inp = torch.randn([1, 3, 512, 512]).to(device)\n",
    "output = model(inp)\n",
    "label = torch.randn([1, 3, 512, 512]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "lossfunc = nn.MSELoss().cuda('0')\n",
    "loss = lossfunc(output,label)\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "037940c5-fdfd-4ba8-b517-d5e7996c2071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13495/711003086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtrainloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# device = 'cuda:0'\n",
    "lr = 0.01\n",
    "epochs = 30\n",
    "lossfunc = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# initializing the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = m2unet().float().to(device)\n",
    "\n",
    "\n",
    "# import torch\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=False)\n",
    "# model = model.to(device)\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trainloss = 0\n",
    "    valloss = 0\n",
    "    \n",
    "    for img,label in tqdm(train_dataloader):\n",
    "        '''\n",
    "            Traning the Model.\n",
    "        '''\n",
    "        optimizer.zero_grad()\n",
    "        # img = img.float().to(device)\n",
    "        # img = img / 256 # pushing data between 0 and 1\n",
    "        # label = label.float().to(device)\n",
    "        \n",
    "        \n",
    "  \n",
    "\n",
    "        output = model(img)\n",
    "    \n",
    "\n",
    "\n",
    "        loss = lossfunc(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trainloss+=loss.item()\n",
    "    \n",
    "    # if(i%5==0):\n",
    "    #     show(img,output,label)\n",
    "\n",
    "    train_loss.append(trainloss/len(train_dataloader))    \n",
    "    \n",
    "  \n",
    "    for img,label in tqdm(test_dataloader):\n",
    "        '''\n",
    "            Validation of Model.\n",
    "        '''\n",
    "        img = img.float().to(device)\n",
    "        # img = img / 256 # pushing data between 0 and 1\n",
    "\n",
    "        label = label.float().to(device)\n",
    "       \n",
    "        \n",
    "        output = model(img)\n",
    "        loss = lossfunc(output,label)\n",
    "        valloss+=loss.item()\n",
    "        \n",
    "    val_loss.append(valloss/len(test_dataloader))  \n",
    "    \n",
    "    \n",
    "    print(\"epoch : {} ,train loss : {} ,valid loss : {} \".format(i,train_loss[-1],val_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00628cf8-877e-4011-a1e8-050ba3e30a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M2UNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decode4): DecoderBlock(\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (ir1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=19, bias=False)\n",
      "        (4): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(19, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decode3): DecoderBlock(\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (ir1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(88, 13, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(13, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=13, bias=False)\n",
      "        (4): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(13, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decode2): DecoderBlock(\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (ir1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(60, 9, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
      "        (4): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(9, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decode1): LastDecoderBlock(\n",
      "    (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (ir1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(33, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=5, bias=False)\n",
      "        (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(5, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d72602-362d-47d9-9a55-0dc6260af602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e575803-1ba4-49d9-9f13-f87c1e28a4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9584bdfe-c23d-4f9c-a48a-f792d6622d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int 8 representation\n",
      "tensor([[[[-1.5655e-02,  0.0000e+00, -2.1157e-01,  ..., -9.5360e-02,\n",
      "           -7.9967e-01, -8.8640e-02],\n",
      "          [ 1.1227e+00, -5.2000e-02,  4.3118e-03,  ..., -1.2355e+00,\n",
      "            3.9822e-01, -1.5442e-01],\n",
      "          [ 0.0000e+00,  1.7486e-02, -8.0632e-01,  ..., -6.8937e-02,\n",
      "           -1.5380e-01, -3.2037e-01],\n",
      "          ...,\n",
      "          [-1.4420e-01, -3.2006e-01,  1.1651e-01,  ...,  7.7434e-04,\n",
      "            0.0000e+00, -5.7113e-01],\n",
      "          [-2.7983e-02,  0.0000e+00, -1.4986e-01,  ..., -4.4771e-01,\n",
      "           -1.7668e-01, -7.3771e-02],\n",
      "          [ 1.2051e-01, -1.5152e-01, -8.0815e-02,  ...,  3.5844e-01,\n",
      "            1.1387e-01, -1.4657e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00, -6.7369e-02,  ..., -6.1453e-01,\n",
      "            1.4655e-03, -4.5894e-02],\n",
      "          [ 1.2854e-01, -4.5373e-01, -2.2768e-02,  ..., -1.7746e-01,\n",
      "            6.1693e-01, -2.7818e-02],\n",
      "          [ 6.3584e-02,  8.2484e-03, -9.2906e-03,  ..., -4.2971e-02,\n",
      "           -5.9451e-01, -1.2292e-01],\n",
      "          ...,\n",
      "          [-1.1948e-01,  2.7354e-01, -2.0534e-01,  ...,  8.7845e-03,\n",
      "           -1.6649e-01, -1.3429e-01],\n",
      "          [-6.6333e-02, -5.8021e-01, -1.0394e-01,  ..., -1.0501e-02,\n",
      "           -3.0490e-01, -1.0622e-02],\n",
      "          [ 4.6075e-01,  1.3152e-01, -1.0644e-01,  ..., -3.1003e-02,\n",
      "            0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1821e-04, -2.7246e-01, -1.4934e-01,  ..., -1.2415e-01,\n",
      "            0.0000e+00, -3.4434e-01],\n",
      "          [-2.6056e-01, -2.0034e-01, -1.6360e-01,  ..., -5.7505e-01,\n",
      "           -3.9208e-01, -2.4287e-01],\n",
      "          [ 1.0957e+00,  2.7091e-03,  1.5563e-01,  ..., -2.5446e-02,\n",
      "           -6.0512e-01, -2.5646e-01],\n",
      "          ...,\n",
      "          [-2.1897e-01,  4.8513e-01,  1.6877e-01,  ..., -4.3829e-01,\n",
      "           -3.1953e-01,  0.0000e+00],\n",
      "          [-5.6799e-02, -7.2313e-01,  6.2351e-01,  ...,  2.2237e-02,\n",
      "           -4.1136e-01, -2.6039e-01],\n",
      "          [-1.3732e-01, -1.5089e-01,  4.9067e-04,  ...,  2.1228e-01,\n",
      "           -4.8395e-02, -1.9787e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.7374e-01, -5.3878e-01, -7.5873e-02,  ..., -7.2661e-01,\n",
      "           -4.1564e-01, -3.9254e-02],\n",
      "          [ 0.0000e+00,  1.0002e-03, -2.3893e-01,  ..., -3.2583e-01,\n",
      "           -7.2031e-02, -1.0953e-01],\n",
      "          [-2.9458e-01, -3.8478e-02, -2.1638e-01,  ...,  8.0288e-04,\n",
      "           -1.6494e-01, -8.3153e-01],\n",
      "          ...,\n",
      "          [-2.8043e-01,  1.7758e-02, -3.8704e-02,  ..., -2.1432e-02,\n",
      "           -1.1221e-01, -3.2331e-01],\n",
      "          [ 5.4084e-01, -1.2868e-01, -2.3915e-01,  ..., -1.7314e-01,\n",
      "            0.0000e+00, -2.3701e-01],\n",
      "          [-7.8606e-02, -4.1322e-01, -3.7655e-02,  ...,  8.4335e-01,\n",
      "           -2.9953e-01, -2.2022e-01]]]], grad_fn=<ConvolutionBackward0>)\n",
      "full precision model\n",
      "tensor([[[[-6.4137e-01,  4.0409e-01, -1.5832e-01,  ...,  4.3909e-01,\n",
      "            4.3909e-01,  4.3909e-01],\n",
      "          [ 8.1809e+00,  2.9074e+00, -8.4465e-01,  ..., -1.0621e+00,\n",
      "            5.8589e-01,  1.2214e+00],\n",
      "          [ 4.2145e+00,  4.3096e+00,  6.4991e-01,  ...,  8.7925e-01,\n",
      "            2.7910e+00,  2.6788e+00],\n",
      "          ...,\n",
      "          [ 1.9889e+00, -7.6730e-01,  1.8885e+00,  ...,  2.2921e-01,\n",
      "            8.8982e-01, -6.2436e-01],\n",
      "          [ 8.3787e-01,  9.2294e-01,  7.0230e-01,  ...,  1.1158e+00,\n",
      "            9.5562e-01, -4.4239e-01],\n",
      "          [ 7.8361e-01,  1.8121e+00,  1.6660e-01,  ...,  1.2561e+00,\n",
      "            7.4707e-01,  6.7113e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.6762e-01, -3.5679e-02,  3.0736e-01,  ..., -1.3795e+00,\n",
      "            2.6507e-01,  1.3172e+00],\n",
      "          [ 3.5137e+00,  4.1818e+00,  3.1664e+00,  ...,  1.5747e+00,\n",
      "            3.8329e+00,  2.0925e+00],\n",
      "          [ 4.1030e+00,  1.3172e+00,  1.3172e+00,  ...,  1.7669e+00,\n",
      "            3.8341e+00,  9.6770e-01],\n",
      "          ...,\n",
      "          [ 3.2000e+00, -6.6818e-01, -1.5531e+00,  ...,  1.0091e-02,\n",
      "            2.9181e-01, -1.3760e-01],\n",
      "          [ 4.2531e+00, -3.1801e+00, -5.8514e-01,  ..., -8.3953e-01,\n",
      "           -6.6077e-01,  4.3909e-01],\n",
      "          [ 9.8873e-01,  8.7865e-01, -2.6410e-02,  ...,  1.3737e-01,\n",
      "            2.5887e-01,  4.3909e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8961e-01,  1.9658e+00, -9.1417e-01,  ...,  6.7983e-01,\n",
      "            1.5607e+00,  2.1934e+00],\n",
      "          [-1.3177e-01,  2.3010e-02, -2.1553e+00,  ...,  8.5557e-02,\n",
      "            2.4037e+00,  3.1291e+00],\n",
      "          [ 1.1598e+00, -1.0380e+00,  2.7262e+00,  ..., -4.1353e-01,\n",
      "            8.6307e-01,  2.7437e+00],\n",
      "          ...,\n",
      "          [ 2.2318e+00,  6.0669e-02, -9.5885e-01,  ...,  3.0028e-01,\n",
      "            4.3909e-01,  4.3909e-01],\n",
      "          [ 2.1186e+00, -1.4461e+00, -1.3291e+00,  ..., -7.5537e-02,\n",
      "           -4.9326e-01,  3.4074e-01],\n",
      "          [ 4.0810e-01,  5.0323e-01,  3.8864e-01,  ...,  4.3909e-01,\n",
      "            4.3909e-01,  5.4926e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8309e-01, -1.9911e-01,  1.4655e-01,  ..., -4.0738e+00,\n",
      "           -1.4110e+00,  3.3834e-01],\n",
      "          [-2.8447e-01,  1.6072e-01,  2.9130e+00,  ..., -9.7093e-01,\n",
      "           -7.6584e-01,  8.7172e-01],\n",
      "          [ 2.3864e-01,  1.2621e+00,  1.2845e+00,  ..., -3.8361e+00,\n",
      "            2.1414e+00,  1.3172e+00],\n",
      "          ...,\n",
      "          [ 2.5981e+00,  1.8993e+00, -1.4752e+00,  ...,  5.9764e+00,\n",
      "            9.6812e+00, -4.1901e+00],\n",
      "          [ 3.9449e+00, -1.4139e+00, -8.6834e-01,  ..., -3.0485e+00,\n",
      "           -3.5310e+00,  2.4196e+00],\n",
      "          [ 1.4677e-01,  1.7613e-03,  4.6647e-01,  ...,  1.8435e+00,\n",
      "            1.5098e+00,  1.7484e-01]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# define a floating point model\n",
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# create a model instance\n",
    "model_fp32 = m2unet()\n",
    "# create a quantized model instance\n",
    "model_int8 = torch.quantization.quantize_dynamic(\n",
    "    model_fp32,  # the original model\n",
    "    {torch.nn.Conv2d},  # a set of layers to dynamically quantize\n",
    "    dtype=torch.qint8)  # the target dtype for quantized weights\n",
    "\n",
    "# run the model\n",
    "input_fp32 = torch.randn(4, 3, 512, 512)\n",
    "res = model_int8(input_fp32)\n",
    "print('int 8 representation')\n",
    "print(res)\n",
    "print('full precision model')\n",
    "print(model_fp32(input_fp32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e3d8156f-b2f4-462a-b476-3eb3e6c9fef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jupyter/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=False)\n",
    "print(model(inp)['out'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83954e20-17f0-4ae7-863d-d7e3fbb7a5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jupyter/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): FCNHead(\n",
       "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet50', pretrained=False)\n",
    "# or\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'fcn_resnet101', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "inp = \n",
    "\n",
    "\n",
    "      (unit3): ResUnit(\n",
    "        (body): ResBottleneck(\n",
    "          (conv1): ConvBlock(\n",
    "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (activ): ReLU(inplace=True)\n",
    "          )\n",
    "          (conv2): ConvBlock(\n",
    "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            (activ): ReLU(inplace=True)\n",
    "          )\n",
    "          (conv3): ConvBlock(\n",
    "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f293bf99-edfd-41a1-b59d-95b06941f551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "inp = torch.randn(1,3,512,512)\n",
    "output = model(inp)\n",
    "# print(output)\n",
    "print(len(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbbd0927-5da3-41ff-b79c-956b9880c767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 21, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "print(output['out'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4e291a87-d022-41e3-b03e-08f284353c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "# from .common import conv1x1_block, conv3x3_block, conv7x7_block\n",
    "# from common import conv1x1_block, conv3x3_block, conv7x7_block\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple ResNet block for residual path in ResNet unit.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 bias=False,\n",
    "                 use_bn=True):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = conv3x3_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=stride,\n",
    "            bias=bias,\n",
    "            use_bn=use_bn)\n",
    "        self.conv2 = conv3x3_block(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            bias=bias,\n",
    "            use_bn=use_bn,\n",
    "            activation=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResBottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck block for residual path in ResNet unit.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for the second convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for the second convolution layer.\n",
    "    conv1_stride : bool, default False\n",
    "        Whether to use stride in the first or the second convolution layer of the block.\n",
    "    bottleneck_factor : int, default 4\n",
    "        Bottleneck factor.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 conv1_stride=False,\n",
    "                 bottleneck_factor=4):\n",
    "        super(ResBottleneck, self).__init__()\n",
    "        mid_channels = out_channels // bottleneck_factor\n",
    "\n",
    "        self.conv1 = conv1x1_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=mid_channels,\n",
    "            stride=(stride if conv1_stride else 1))\n",
    "        self.conv2 = conv3x3_block(\n",
    "            in_channels=mid_channels,\n",
    "            out_channels=mid_channels,\n",
    "            stride=(1 if conv1_stride else stride),\n",
    "            padding=padding,\n",
    "            dilation=dilation)\n",
    "        self.conv3 = conv1x1_block(\n",
    "            in_channels=mid_channels,\n",
    "            out_channels=out_channels,\n",
    "            activation=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResUnit(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet unit with residual connection.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for the second convolution layer in bottleneck.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for the second convolution layer in bottleneck.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bottleneck : bool, default True\n",
    "        Whether to use a bottleneck or simple block in units.\n",
    "    conv1_stride : bool, default False\n",
    "        Whether to use stride in the first or the second convolution layer of the block.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bottleneck=True,\n",
    "                 conv1_stride=False):\n",
    "        super(ResUnit, self).__init__()\n",
    "        self.resize_identity = (in_channels != out_channels) or (stride != 1)\n",
    "\n",
    "        if bottleneck:\n",
    "            self.body = ResBottleneck(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                conv1_stride=conv1_stride)\n",
    "        else:\n",
    "            self.body = ResBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                stride=stride,\n",
    "                bias=bias,\n",
    "                use_bn=use_bn)\n",
    "        if self.resize_identity:\n",
    "            self.identity_conv = conv1x1_block(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                stride=stride,\n",
    "                bias=bias,\n",
    "                use_bn=use_bn,\n",
    "                activation=None)\n",
    "        self.activ = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.resize_identity:\n",
    "            identity = self.identity_conv(x)\n",
    "        else:\n",
    "            identity = x\n",
    "        x = self.body(x)\n",
    "        x = x + identity\n",
    "        x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResInitBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet specific initial block.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels):\n",
    "        super(ResInitBlock, self).__init__()\n",
    "        self.conv = conv7x7_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=2)\n",
    "        self.pool = nn.MaxPool2d(\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : list of list of int\n",
    "        Number of output channels for each unit.\n",
    "    init_block_channels : int\n",
    "        Number of output channels for the initial unit.\n",
    "    bottleneck : bool\n",
    "        Whether to use a bottleneck or simple block in units.\n",
    "    conv1_stride : bool\n",
    "        Whether to use stride in the first or the second convolution layer in units.\n",
    "    in_channels : int, default 3\n",
    "        Number of input channels.\n",
    "    in_size : tuple of two ints, default (224, 224)\n",
    "        Spatial size of the expected input image.\n",
    "    num_classes : int, default 1000\n",
    "        Number of classification classes.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 init_block_channels,\n",
    "                 bottleneck,\n",
    "                 conv1_stride,\n",
    "                 in_channels=3,\n",
    "                 in_size=(224, 224),\n",
    "                 num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module(\"init_block\", ResInitBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=init_block_channels))\n",
    "        in_channels = init_block_channels\n",
    "        for i, channels_per_stage in enumerate(channels):\n",
    "            stage = nn.Sequential()\n",
    "            for j, out_channels in enumerate(channels_per_stage):\n",
    "                stride = 2 if (j == 0) and (i != 0) else 1\n",
    "                stage.add_module(\"unit{}\".format(j + 1), ResUnit(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    stride=stride,\n",
    "                    bottleneck=bottleneck,\n",
    "                    conv1_stride=conv1_stride))\n",
    "                in_channels = out_channels\n",
    "            self.features.add_module(\"stage{}\".format(i + 1), stage)\n",
    "        # self.features.add_module(\"final_pool\", nn.AvgPool2d(\n",
    "        #     kernel_size=7,\n",
    "        #     stride=1))\n",
    "\n",
    "        # self.output = nn.Linear(\n",
    "        #     in_features=in_channels,\n",
    "        #     out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drp1 = nn.Dropout(p=0.1, inplace=False)\n",
    "        self.conv2 = nn.Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "        self._init_params()\n",
    "\n",
    "    def _init_params(self):\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.drp1(x)\n",
    "        x = self.conv2(x)\n",
    "    \n",
    "        \n",
    "        # # Old code\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.output(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "#     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (2): ReLU()\n",
    "#     (3): Dropout(p=0.1, inplace=False)\n",
    "#     (4): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
    "\n",
    "\n",
    "def get_resnet(blocks,\n",
    "               bottleneck=None,\n",
    "               conv1_stride=True,\n",
    "               width_scale=1.0,\n",
    "               model_name=None,\n",
    "               pretrained=False,\n",
    "               root=os.path.join(\"~\", \".torch\", \"models\"),\n",
    "               **kwargs):\n",
    "    \"\"\"\n",
    "    Create ResNet model with specific parameters.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    blocks : int\n",
    "        Number of blocks.\n",
    "    bottleneck : bool, default None\n",
    "        Whether to use a bottleneck or simple block in units.\n",
    "    conv1_stride : bool, default True\n",
    "        Whether to use stride in the first or the second convolution layer in units.\n",
    "    width_scale : float, default 1.0\n",
    "        Scale factor for width of layers.\n",
    "    model_name : str or None, default None\n",
    "        Model name for loading pretrained model.\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    if bottleneck is None:\n",
    "        bottleneck = (blocks >= 50)\n",
    "\n",
    "    if blocks == 10:\n",
    "        layers = [1, 1, 1, 1]\n",
    "    elif blocks == 12:\n",
    "        layers = [2, 1, 1, 1]\n",
    "    elif blocks == 14 and not bottleneck:\n",
    "        layers = [2, 2, 1, 1]\n",
    "    elif (blocks == 14) and bottleneck:\n",
    "        layers = [1, 1, 1, 1]\n",
    "    elif blocks == 16:\n",
    "        layers = [2, 2, 2, 1]\n",
    "    elif blocks == 18:\n",
    "        layers = [2, 2, 2, 2]\n",
    "    elif (blocks == 26) and not bottleneck:\n",
    "        layers = [3, 3, 3, 3]\n",
    "    elif (blocks == 26) and bottleneck:\n",
    "        layers = [2, 2, 2, 2]\n",
    "    elif blocks == 34:\n",
    "        layers = [3, 4, 6, 3]\n",
    "    elif (blocks == 38) and bottleneck:\n",
    "        layers = [3, 3, 3, 3]\n",
    "    elif blocks == 50:\n",
    "        layers = [3, 4, 6, 3]\n",
    "    elif blocks == 101:\n",
    "        layers = [3, 4, 23, 3]\n",
    "    elif blocks == 152:\n",
    "        layers = [3, 8, 36, 3]\n",
    "    elif blocks == 200:\n",
    "        layers = [3, 24, 36, 3]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported ResNet with number of blocks: {}\".format(blocks))\n",
    "\n",
    "    if bottleneck:\n",
    "        assert (sum(layers) * 3 + 2 == blocks)\n",
    "    else:\n",
    "        assert (sum(layers) * 2 + 2 == blocks)\n",
    "\n",
    "    init_block_channels = 64\n",
    "    channels_per_layers = [64, 128, 256, 512]\n",
    "\n",
    "    if bottleneck:\n",
    "        bottleneck_factor = 4\n",
    "        channels_per_layers = [ci * bottleneck_factor for ci in channels_per_layers]\n",
    "\n",
    "    channels = [[ci] * li for (ci, li) in zip(channels_per_layers, layers)]\n",
    "\n",
    "    if width_scale != 1.0:\n",
    "        channels = [[int(cij * width_scale) if (i != len(channels) - 1) or (j != len(ci) - 1) else cij\n",
    "                     for j, cij in enumerate(ci)] for i, ci in enumerate(channels)]\n",
    "        init_block_channels = int(init_block_channels * width_scale)\n",
    "\n",
    "    net = ResNet(\n",
    "        channels=channels,\n",
    "        init_block_channels=init_block_channels,\n",
    "        bottleneck=bottleneck,\n",
    "        conv1_stride=conv1_stride,\n",
    "        **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        if (model_name is None) or (not model_name):\n",
    "            raise ValueError(\"Parameter `model_name` should be properly initialized for loading pretrained model.\")\n",
    "        from .model_store import download_model\n",
    "        download_model(\n",
    "            net=net,\n",
    "            model_name=model_name,\n",
    "            local_model_store_dir_path=root)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def resnet10(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-10 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=10, model_name=\"resnet10\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet12(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-12 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=12, model_name=\"resnet12\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet14(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-14 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=14, model_name=\"resnet14\", **kwargs)\n",
    "\n",
    "\n",
    "def resnetbc14b(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-BC-14b model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model (bottleneck compressed).\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=14, bottleneck=True, conv1_stride=False, model_name=\"resnetbc14b\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet16(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-16 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=16, model_name=\"resnet16\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet18_wd4(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-18 model with 0.25 width scale from 'Deep Residual Learning for Image Recognition,'\n",
    "    https://arxiv.org/abs/1512.03385. It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=18, width_scale=0.25, model_name=\"resnet18_wd4\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet18_wd2(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-18 model with 0.5 width scale from 'Deep Residual Learning for Image Recognition,'\n",
    "    https://arxiv.org/abs/1512.03385. It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=18, width_scale=0.5, model_name=\"resnet18_wd2\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet18_w3d4(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-18 model with 0.75 width scale from 'Deep Residual Learning for Image Recognition,'\n",
    "    https://arxiv.org/abs/1512.03385. It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=18, width_scale=0.75, model_name=\"resnet18_w3d4\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet18(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-18 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=18, model_name=\"resnet18\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet26(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-26 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=26, bottleneck=False, model_name=\"resnet26\", **kwargs)\n",
    "\n",
    "\n",
    "def resnetbc26b(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-BC-26b model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model (bottleneck compressed).\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=26, bottleneck=True, conv1_stride=False, model_name=\"resnetbc26b\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-34 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=34, model_name=\"resnet34\", **kwargs)\n",
    "\n",
    "\n",
    "def resnetbc38b(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-BC-38b model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    It's an experimental model (bottleneck compressed).\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=38, bottleneck=True, conv1_stride=False, model_name=\"resnetbc38b\", **kwargs)\n",
    "\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    \"\"\"\n",
    "    ResNet-50 model from 'Deep Residual Learning for Image Recognition,' https://arxiv.org/abs/1512.03385.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    pretrained : bool, default False\n",
    "        Whether to load the pretrained weights for model.\n",
    "    root : str, default '~/.torch/models'\n",
    "        Location for keeping the model parameters.\n",
    "    \"\"\"\n",
    "    return get_resnet(blocks=50, model_name=\"resnet50\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "438554f7-a85f-46f4-8bc4-5e0977f32264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 16, 16])\n",
      "ResNet(\n",
      "  (features): Sequential(\n",
      "    (init_block): ResInitBlock(\n",
      "      (conv): ConvBlock(\n",
      "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (stage1): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage2): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit4): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit4): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit5): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit6): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (stage4): Sequential(\n",
      "      (unit1): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (identity_conv): ConvBlock(\n",
      "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit2): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "      (unit3): ResUnit(\n",
      "        (body): ResBottleneck(\n",
      "          (conv1): ConvBlock(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv2): ConvBlock(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activ): ReLU(inplace=True)\n",
      "          )\n",
      "          (conv3): ConvBlock(\n",
      "            (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activ): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU()\n",
      "  (drp1): Dropout(p=0.1, inplace=False)\n",
      "  (conv2): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = resnet50()\n",
    "inp = torch.randn(1,3,512,512)\n",
    "print(model(inp).shape)\n",
    "print(model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14086dc2-726b-4137-b4a8-d64f8c0f0492",
   "metadata": {},
   "outputs": [],
   "source": [
    " )\n",
    "      (2): Bottleneck(\n",
    "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
    "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        (relu): ReLU(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ff38e-8487-4bef-9325-3172cd3d4449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d90bf05f-82be-4fe5-97ad-1e6f1278b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Common routines for models in PyTorch.\n",
    "\"\"\"\n",
    "\n",
    "__all__ = ['round_channels', 'Identity', 'BreakBlock', 'Swish', 'HSigmoid', 'HSwish', 'get_activation_layer',\n",
    "           'SelectableDense', 'DenseBlock', 'ConvBlock1d', 'conv1x1', 'conv3x3', 'depthwise_conv3x3', 'ConvBlock',\n",
    "           'conv1x1_block', 'conv3x3_block', 'conv5x5_block', 'conv7x7_block', 'dwconv_block', 'dwconv3x3_block',\n",
    "           'dwconv5x5_block', 'dwsconv3x3_block', 'PreConvBlock', 'pre_conv1x1_block', 'pre_conv3x3_block',\n",
    "           'AsymConvBlock', 'asym_conv3x3_block', 'DeconvBlock', 'deconv3x3_block', 'NormActivation',\n",
    "           'InterpolationBlock', 'ChannelShuffle', 'ChannelShuffle2', 'SEBlock', 'SABlock', 'SAConvBlock',\n",
    "           'saconv3x3_block', 'DucBlock', 'IBN', 'DualPathSequential', 'Concurrent', 'SequentialConcurrent',\n",
    "           'ParametricSequential', 'ParametricConcurrent', 'Hourglass', 'SesquialteralHourglass',\n",
    "           'MultiOutputSequential', 'ParallelConcurent', 'DualPathParallelConcurent', 'Flatten', 'HeatmapMaxDetBlock']\n",
    "\n",
    "import math\n",
    "from inspect import isfunction\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "def round_channels(channels,\n",
    "                   divisor=8):\n",
    "    \"\"\"\n",
    "    Round weighted channel number (make divisible operation).\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int or float\n",
    "        Original number of channels.\n",
    "    divisor : int, default 8\n",
    "        Alignment value.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    int\n",
    "        Weighted number of channels.\n",
    "    \"\"\"\n",
    "    rounded_channels = max(int(channels + divisor / 2.0) // divisor * divisor, divisor)\n",
    "    if float(rounded_channels) < 0.9 * channels:\n",
    "        rounded_channels += divisor\n",
    "    return rounded_channels\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    \"\"\"\n",
    "    Identity block.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{name}()'.format(name=self.__class__.__name__)\n",
    "\n",
    "\n",
    "class BreakBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Break coonnection block for hourglass.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BreakBlock, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{name}()'.format(name=self.__class__.__name__)\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "    Swish activation function from 'Searching for Activation Functions,' https://arxiv.org/abs/1710.05941.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class HSigmoid(nn.Module):\n",
    "    \"\"\"\n",
    "    Approximated sigmoid function, so-called hard-version of sigmoid from 'Searching for MobileNetV3,'\n",
    "    https://arxiv.org/abs/1905.02244.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return F.relu6(x + 3.0, inplace=True) / 6.0\n",
    "\n",
    "\n",
    "class HSwish(nn.Module):\n",
    "    \"\"\"\n",
    "    H-Swish activation function from 'Searching for MobileNetV3,' https://arxiv.org/abs/1905.02244.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    inplace : bool\n",
    "        Whether to use inplace version of the module.\n",
    "    \"\"\"\n",
    "    def __init__(self, inplace=False):\n",
    "        super(HSwish, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * F.relu6(x + 3.0, inplace=self.inplace) / 6.0\n",
    "\n",
    "\n",
    "def get_activation_layer(activation):\n",
    "    \"\"\"\n",
    "    Create activation layer from string/function.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    activation : function, or str, or nn.Module\n",
    "        Activation function or name of activation function.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    nn.Module\n",
    "        Activation layer.\n",
    "    \"\"\"\n",
    "    assert (activation is not None)\n",
    "    if isfunction(activation):\n",
    "        return activation()\n",
    "    elif isinstance(activation, str):\n",
    "        if activation == \"relu\":\n",
    "            return nn.ReLU(inplace=True)\n",
    "        elif activation == \"relu6\":\n",
    "            return nn.ReLU6(inplace=True)\n",
    "        elif activation == \"swish\":\n",
    "            return Swish()\n",
    "        elif activation == \"hswish\":\n",
    "            return HSwish(inplace=True)\n",
    "        elif activation == \"sigmoid\":\n",
    "            return nn.Sigmoid()\n",
    "        elif activation == \"hsigmoid\":\n",
    "            return HSigmoid()\n",
    "        elif activation == \"identity\":\n",
    "            return Identity()\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    else:\n",
    "        assert (isinstance(activation, nn.Module))\n",
    "        return activation\n",
    "\n",
    "\n",
    "class SelectableDense(nn.Module):\n",
    "    \"\"\"\n",
    "    Selectable dense layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_features : int\n",
    "        Number of input features.\n",
    "    out_features : int\n",
    "        Number of output features.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    num_options : int, default 1\n",
    "        Number of selectable options.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 bias=False,\n",
    "                 num_options=1):\n",
    "        super(SelectableDense, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = bias\n",
    "        self.num_options = num_options\n",
    "        self.weight = Parameter(torch.Tensor(num_options, out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(num_options, out_features))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, x, indices):\n",
    "        weight = torch.index_select(self.weight, dim=0, index=indices)\n",
    "        x = x.unsqueeze(-1)\n",
    "        x = weight.bmm(x)\n",
    "        x = x.squeeze(dim=-1)\n",
    "        if self.use_bias:\n",
    "            bias = torch.index_select(self.bias, dim=0, index=indices)\n",
    "            x += bias\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"in_features={}, out_features={}, bias={}, num_options={}\".format(\n",
    "            self.in_features, self.out_features, self.use_bias, self.num_options)\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard dense block with Batch normalization and activation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_features : int\n",
    "        Number of input features.\n",
    "    out_features : int\n",
    "        Number of output features.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.activate = (activation is not None)\n",
    "        self.use_bn = use_bn\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            bias=bias)\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm1d(\n",
    "                num_features=out_features,\n",
    "                eps=bn_eps)\n",
    "        if self.activate:\n",
    "            self.activ = get_activation_layer(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.activate:\n",
    "            x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard 1D convolution block with Batch normalization and activation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int\n",
    "        Convolution window size.\n",
    "    stride : int\n",
    "        Strides of the convolution.\n",
    "    padding : int\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(ConvBlock1d, self).__init__()\n",
    "        self.activate = (activation is not None)\n",
    "        self.use_bn = use_bn\n",
    "\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm1d(\n",
    "                num_features=out_channels,\n",
    "                eps=bn_eps)\n",
    "        if self.activate:\n",
    "            self.activ = get_activation_layer(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.activate:\n",
    "            x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def conv1x1(in_channels,\n",
    "            out_channels,\n",
    "            stride=1,\n",
    "            groups=1,\n",
    "            bias=False):\n",
    "    \"\"\"\n",
    "    Convolution 1x1 layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        groups=groups,\n",
    "        bias=bias)\n",
    "\n",
    "\n",
    "def conv3x3(in_channels,\n",
    "            out_channels,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=False):\n",
    "    \"\"\"\n",
    "    Convolution 3x3 layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    "        bias=bias)\n",
    "\n",
    "\n",
    "def depthwise_conv3x3(channels,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      dilation=1,\n",
    "                      bias=False):\n",
    "    \"\"\"\n",
    "    Depthwise convolution 3x3 layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of input/output channels.\n",
    "    strides : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels=channels,\n",
    "        out_channels=channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=channels,\n",
    "        bias=bias)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard convolution block with Batch normalization and activation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int or tuple/list of 2 int\n",
    "        Convolution window size.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.activate = (activation is not None)\n",
    "        self.use_bn = use_bn\n",
    "        self.use_pad = (isinstance(padding, (list, tuple)) and (len(padding) == 4))\n",
    "\n",
    "        if self.use_pad:\n",
    "            self.pad = nn.ZeroPad2d(padding=padding)\n",
    "            padding = 0\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm2d(\n",
    "                num_features=out_channels,\n",
    "                eps=bn_eps)\n",
    "        if self.activate:\n",
    "            self.activ = get_activation_layer(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_pad:\n",
    "            x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.activate:\n",
    "            x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def conv1x1_block(in_channels,\n",
    "                  out_channels,\n",
    "                  stride=1,\n",
    "                  padding=0,\n",
    "                  groups=1,\n",
    "                  bias=False,\n",
    "                  use_bn=True,\n",
    "                  bn_eps=1e-5,\n",
    "                  activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    1x1 version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 0\n",
    "        Padding value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return ConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        groups=groups,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "def conv3x3_block(in_channels,\n",
    "                  out_channels,\n",
    "                  stride=1,\n",
    "                  padding=1,\n",
    "                  dilation=1,\n",
    "                  groups=1,\n",
    "                  bias=False,\n",
    "                  use_bn=True,\n",
    "                  bn_eps=1e-5,\n",
    "                  activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    3x3 version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return ConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "def conv5x5_block(in_channels,\n",
    "                  out_channels,\n",
    "                  stride=1,\n",
    "                  padding=2,\n",
    "                  dilation=1,\n",
    "                  groups=1,\n",
    "                  bias=False,\n",
    "                  use_bn=True,\n",
    "                  bn_eps=1e-5,\n",
    "                  activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    5x5 version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 2\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return ConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=5,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "def conv7x7_block(in_channels,\n",
    "                  out_channels,\n",
    "                  stride=1,\n",
    "                  padding=3,\n",
    "                  dilation=1,\n",
    "                  groups=1,\n",
    "                  bias=False,\n",
    "                  use_bn=True,\n",
    "                  bn_eps=1e-5,\n",
    "                  activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    7x7 version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 3\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return ConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=7,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "def dwconv_block(in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    Depthwise version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int or tuple/list of 2 int\n",
    "        Convolution window size.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return ConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernel_size,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=out_channels,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "def dwconv3x3_block(in_channels,\n",
    "                    out_channels,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    dilation=1,\n",
    "                    bias=False,\n",
    "                    bn_eps=1e-5,\n",
    "                    activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    3x3 depthwise version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return dwconv_block(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=bias,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "def dwconv5x5_block(in_channels,\n",
    "                    out_channels,\n",
    "                    stride=1,\n",
    "                    padding=2,\n",
    "                    dilation=1,\n",
    "                    bias=False,\n",
    "                    bn_eps=1e-5,\n",
    "                    activation=(lambda: nn.ReLU(inplace=True))):\n",
    "    \"\"\"\n",
    "    5x5 depthwise version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 2\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return dwconv_block(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=5,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=bias,\n",
    "        bn_eps=bn_eps,\n",
    "        activation=activation)\n",
    "\n",
    "\n",
    "class DwsConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Depthwise separable convolution block with BatchNorms and activations at each convolution layers.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int or tuple/list of 2 int\n",
    "        Convolution window size.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    dw_use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer (depthwise convolution block).\n",
    "    pw_use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer (pointwise convolution block).\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    dw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the depthwise convolution block.\n",
    "    pw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the pointwise convolution block.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 dilation=1,\n",
    "                 bias=False,\n",
    "                 dw_use_bn=True,\n",
    "                 pw_use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 dw_activation=(lambda: nn.ReLU(inplace=True)),\n",
    "                 pw_activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(DwsConvBlock, self).__init__()\n",
    "        self.dw_conv = dwconv_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            bias=bias,\n",
    "            use_bn=dw_use_bn,\n",
    "            bn_eps=bn_eps,\n",
    "            activation=dw_activation)\n",
    "        self.pw_conv = conv1x1_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            bias=bias,\n",
    "            use_bn=pw_use_bn,\n",
    "            bn_eps=bn_eps,\n",
    "            activation=pw_activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        x = self.pw_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def dwsconv3x3_block(in_channels,\n",
    "                     out_channels,\n",
    "                     stride=1,\n",
    "                     padding=1,\n",
    "                     dilation=1,\n",
    "                     bias=False,\n",
    "                     bn_eps=1e-5,\n",
    "                     dw_activation=(lambda: nn.ReLU(inplace=True)),\n",
    "                     pw_activation=(lambda: nn.ReLU(inplace=True)),\n",
    "                     **kwargs):\n",
    "    \"\"\"\n",
    "    3x3 depthwise separable version of the standard convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    dw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the depthwise convolution block.\n",
    "    pw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the pointwise convolution block.\n",
    "    \"\"\"\n",
    "    return DwsConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=bias,\n",
    "        bn_eps=bn_eps,\n",
    "        dw_activation=dw_activation,\n",
    "        pw_activation=pw_activation,\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "class PreConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution block with Batch normalization and ReLU pre-activation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int or tuple/list of 2 int\n",
    "        Convolution window size.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    return_preact : bool, default False\n",
    "        Whether return pre-activation. It's used by PreResNet.\n",
    "    activate : bool, default True\n",
    "        Whether activate the convolution block.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 dilation=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 return_preact=False,\n",
    "                 activate=True):\n",
    "        super(PreConvBlock, self).__init__()\n",
    "        self.return_preact = return_preact\n",
    "        self.activate = activate\n",
    "        self.use_bn = use_bn\n",
    "\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm2d(num_features=in_channels)\n",
    "        if self.activate:\n",
    "            self.activ = nn.ReLU(inplace=True)\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.activate:\n",
    "            x = self.activ(x)\n",
    "        if self.return_preact:\n",
    "            x_pre_activ = x\n",
    "        x = self.conv(x)\n",
    "        if self.return_preact:\n",
    "            return x, x_pre_activ\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "def pre_conv1x1_block(in_channels,\n",
    "                      out_channels,\n",
    "                      stride=1,\n",
    "                      bias=False,\n",
    "                      use_bn=True,\n",
    "                      return_preact=False,\n",
    "                      activate=True):\n",
    "    \"\"\"\n",
    "    1x1 version of the pre-activated convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    return_preact : bool, default False\n",
    "        Whether return pre-activation.\n",
    "    activate : bool, default True\n",
    "        Whether activate the convolution block.\n",
    "    \"\"\"\n",
    "    return PreConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        padding=0,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        return_preact=return_preact,\n",
    "        activate=activate)\n",
    "\n",
    "\n",
    "def pre_conv3x3_block(in_channels,\n",
    "                      out_channels,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      dilation=1,\n",
    "                      bias=False,\n",
    "                      use_bn=True,\n",
    "                      return_preact=False,\n",
    "                      activate=True):\n",
    "    \"\"\"\n",
    "    3x3 version of the pre-activated convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    return_preact : bool, default False\n",
    "        Whether return pre-activation.\n",
    "    activate : bool, default True\n",
    "        Whether activate the convolution block.\n",
    "    \"\"\"\n",
    "    return PreConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        bias=bias,\n",
    "        use_bn=use_bn,\n",
    "        return_preact=return_preact,\n",
    "        activate=activate)\n",
    "\n",
    "\n",
    "class AsymConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Asymmetric separable convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of input/output channels.\n",
    "    kernel_size : int\n",
    "        Convolution window size.\n",
    "    padding : int\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    lw_use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer (leftwise convolution block).\n",
    "    rw_use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer (rightwise convolution block).\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    lw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the leftwise convolution block.\n",
    "    rw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the rightwise convolution block.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 kernel_size,\n",
    "                 padding,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=False,\n",
    "                 lw_use_bn=True,\n",
    "                 rw_use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 lw_activation=(lambda: nn.ReLU(inplace=True)),\n",
    "                 rw_activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(AsymConvBlock, self).__init__()\n",
    "        self.lw_conv = ConvBlock(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(kernel_size, 1),\n",
    "            stride=1,\n",
    "            padding=(padding, 0),\n",
    "            dilation=(dilation, 1),\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "            use_bn=lw_use_bn,\n",
    "            bn_eps=bn_eps,\n",
    "            activation=lw_activation)\n",
    "        self.rw_conv = ConvBlock(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(1, kernel_size),\n",
    "            stride=1,\n",
    "            padding=(0, padding),\n",
    "            dilation=(1, dilation),\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "            use_bn=rw_use_bn,\n",
    "            bn_eps=bn_eps,\n",
    "            activation=rw_activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lw_conv(x)\n",
    "        x = self.rw_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def asym_conv3x3_block(padding=1,\n",
    "                       **kwargs):\n",
    "    \"\"\"\n",
    "    3x3 asymmetric separable convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of input/output channels.\n",
    "    padding : int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    lw_use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer (leftwise convolution block).\n",
    "    rw_use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer (rightwise convolution block).\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    lw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the leftwise convolution block.\n",
    "    rw_activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function after the rightwise convolution block.\n",
    "    \"\"\"\n",
    "    return AsymConvBlock(\n",
    "        kernel_size=3,\n",
    "        padding=padding,\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Deconvolution block with batch normalization and activation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int or tuple/list of 2 int\n",
    "        Convolution window size.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the deconvolution.\n",
    "    padding : int or tuple/list of 2 int\n",
    "        Padding value for deconvolution layer.\n",
    "    ext_padding : tuple/list of 4 int, default None\n",
    "        Extra padding value for deconvolution layer.\n",
    "    out_padding : int or tuple/list of 2 int\n",
    "        Output padding value for deconvolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for deconvolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 ext_padding=None,\n",
    "                 out_padding=0,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        self.activate = (activation is not None)\n",
    "        self.use_bn = use_bn\n",
    "        self.use_pad = (ext_padding is not None)\n",
    "\n",
    "        if self.use_pad:\n",
    "            self.pad = nn.ZeroPad2d(padding=ext_padding)\n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            output_padding=out_padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias)\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm2d(\n",
    "                num_features=out_channels,\n",
    "                eps=bn_eps)\n",
    "        if self.activate:\n",
    "            self.activ = get_activation_layer(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_pad:\n",
    "            x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.activate:\n",
    "            x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def deconv3x3_block(padding=1,\n",
    "                    out_padding=1,\n",
    "                    **kwargs):\n",
    "    \"\"\"\n",
    "    3x3 version of the deconvolution block with batch normalization and activation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the deconvolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for deconvolution layer.\n",
    "    ext_padding : tuple/list of 4 int, default None\n",
    "        Extra padding value for deconvolution layer.\n",
    "    out_padding : int or tuple/list of 2 int, default 1\n",
    "        Output padding value for deconvolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for deconvolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    return DeconvBlock(\n",
    "        kernel_size=3,\n",
    "        padding=padding,\n",
    "        out_padding=out_padding,\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "class NormActivation(nn.Module):\n",
    "    \"\"\"\n",
    "    Activation block with preliminary batch normalization. It's used by itself as the final block in PreResNet.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(NormActivation, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            num_features=in_channels,\n",
    "            eps=bn_eps)\n",
    "        self.activ = get_activation_layer(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.activ(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InterpolationBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Interpolation upsampling block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    scale_factor : int\n",
    "        Multiplier for spatial size.\n",
    "    out_size : tuple of 2 int, default None\n",
    "        Spatial size of the output tensor for the bilinear interpolation operation.\n",
    "    mode : str, default 'bilinear'\n",
    "        Algorithm used for upsampling.\n",
    "    align_corners : bool, default True\n",
    "        Whether to align the corner pixels of the input and output tensors.\n",
    "    up : bool, default True\n",
    "        Whether to upsample or downsample.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 scale_factor,\n",
    "                 out_size=None,\n",
    "                 mode=\"bilinear\",\n",
    "                 align_corners=True,\n",
    "                 up=True):\n",
    "        super(InterpolationBlock, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.out_size = out_size\n",
    "        self.mode = mode\n",
    "        self.align_corners = align_corners\n",
    "        self.up = up\n",
    "\n",
    "    def forward(self, x, size=None):\n",
    "        if (self.mode == \"bilinear\") or (size is not None):\n",
    "            out_size = self.calc_out_size(x) if size is None else size\n",
    "            return F.interpolate(\n",
    "                input=x,\n",
    "                size=out_size,\n",
    "                mode=self.mode,\n",
    "                align_corners=self.align_corners)\n",
    "        else:\n",
    "            return F.interpolate(\n",
    "                input=x,\n",
    "                scale_factor=self.scale_factor,\n",
    "                mode=self.mode,\n",
    "                align_corners=self.align_corners)\n",
    "\n",
    "    def calc_out_size(self, x):\n",
    "        if self.out_size is not None:\n",
    "            return self.out_size\n",
    "        if self.up:\n",
    "            return tuple(s * self.scale_factor for s in x.shape[2:])\n",
    "        else:\n",
    "            return tuple(s // self.scale_factor for s in x.shape[2:])\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = '{name}(scale_factor={scale_factor}, out_size={out_size}, mode={mode}, align_corners={align_corners}, up={up})' # noqa\n",
    "        return s.format(\n",
    "            name=self.__class__.__name__,\n",
    "            scale_factor=self.scale_factor,\n",
    "            out_size=self.out_size,\n",
    "            mode=self.mode,\n",
    "            align_corners=self.align_corners,\n",
    "            up=self.up)\n",
    "\n",
    "    def calc_flops(self, x):\n",
    "        assert (x.shape[0] == 1)\n",
    "        if self.mode == \"bilinear\":\n",
    "            num_flops = 9 * x.numel()\n",
    "        else:\n",
    "            num_flops = 4 * x.numel()\n",
    "        num_macs = 0\n",
    "        return num_flops, num_macs\n",
    "\n",
    "\n",
    "def channel_shuffle(x,\n",
    "                    groups):\n",
    "    \"\"\"\n",
    "    Channel shuffle operation from 'ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,'\n",
    "    https://arxiv.org/abs/1707.01083.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    x : Tensor\n",
    "        Input tensor.\n",
    "    groups : int\n",
    "        Number of groups.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Tensor\n",
    "        Resulted tensor.\n",
    "    \"\"\"\n",
    "    batch, channels, height, width = x.size()\n",
    "    # assert (channels % groups == 0)\n",
    "    channels_per_group = channels // groups\n",
    "    x = x.view(batch, groups, channels_per_group, height, width)\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "    x = x.view(batch, channels, height, width)\n",
    "    return x\n",
    "\n",
    "\n",
    "class ChannelShuffle(nn.Module):\n",
    "    \"\"\"\n",
    "    Channel shuffle layer. This is a wrapper over the same operation. It is designed to save the number of groups.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of channels.\n",
    "    groups : int\n",
    "        Number of groups.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 groups):\n",
    "        super(ChannelShuffle, self).__init__()\n",
    "        # assert (channels % groups == 0)\n",
    "        if channels % groups != 0:\n",
    "            raise ValueError(\"channels must be divisible by groups\")\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        return channel_shuffle(x, self.groups)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"{name}(groups={groups})\"\n",
    "        return s.format(\n",
    "            name=self.__class__.__name__,\n",
    "            groups=self.groups)\n",
    "\n",
    "\n",
    "def channel_shuffle2(x,\n",
    "                     groups):\n",
    "    \"\"\"\n",
    "    Channel shuffle operation from 'ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices,'\n",
    "    https://arxiv.org/abs/1707.01083. The alternative version.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    x : Tensor\n",
    "        Input tensor.\n",
    "    groups : int\n",
    "        Number of groups.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    Tensor\n",
    "        Resulted tensor.\n",
    "    \"\"\"\n",
    "    batch, channels, height, width = x.size()\n",
    "    # assert (channels % groups == 0)\n",
    "    channels_per_group = channels // groups\n",
    "    x = x.view(batch, channels_per_group, groups, height, width)\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "    x = x.view(batch, channels, height, width)\n",
    "    return x\n",
    "\n",
    "\n",
    "class ChannelShuffle2(nn.Module):\n",
    "    \"\"\"\n",
    "    Channel shuffle layer. This is a wrapper over the same operation. It is designed to save the number of groups.\n",
    "    The alternative version.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of channels.\n",
    "    groups : int\n",
    "        Number of groups.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 groups):\n",
    "        super(ChannelShuffle2, self).__init__()\n",
    "        # assert (channels % groups == 0)\n",
    "        if channels % groups != 0:\n",
    "            raise ValueError(\"channels must be divisible by groups\")\n",
    "        self.groups = groups\n",
    "\n",
    "    def forward(self, x):\n",
    "        return channel_shuffle2(x, self.groups)\n",
    "\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation block from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of channels.\n",
    "    reduction : int, default 16\n",
    "        Squeeze reduction value.\n",
    "    mid_channels : int or None, default None\n",
    "        Number of middle channels.\n",
    "    round_mid : bool, default False\n",
    "        Whether to round middle channel number (make divisible by 8).\n",
    "    use_conv : bool, default True\n",
    "        Whether to convolutional layers instead of fully-connected ones.\n",
    "    activation : function, or str, or nn.Module, default 'relu'\n",
    "        Activation function after the first convolution.\n",
    "    out_activation : function, or str, or nn.Module, default 'sigmoid'\n",
    "        Activation function after the last convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 reduction=16,\n",
    "                 mid_channels=None,\n",
    "                 round_mid=False,\n",
    "                 use_conv=True,\n",
    "                 mid_activation=(lambda: nn.ReLU(inplace=True)),\n",
    "                 out_activation=(lambda: nn.Sigmoid())):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.use_conv = use_conv\n",
    "        if mid_channels is None:\n",
    "            mid_channels = channels // reduction if not round_mid else round_channels(float(channels) / reduction)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        if use_conv:\n",
    "            self.conv1 = conv1x1(\n",
    "                in_channels=channels,\n",
    "                out_channels=mid_channels,\n",
    "                bias=True)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(\n",
    "                in_features=channels,\n",
    "                out_features=mid_channels)\n",
    "        self.activ = get_activation_layer(mid_activation)\n",
    "        if use_conv:\n",
    "            self.conv2 = conv1x1(\n",
    "                in_channels=mid_channels,\n",
    "                out_channels=channels,\n",
    "                bias=True)\n",
    "        else:\n",
    "            self.fc2 = nn.Linear(\n",
    "                in_features=mid_channels,\n",
    "                out_features=channels)\n",
    "        self.sigmoid = get_activation_layer(out_activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.pool(x)\n",
    "        if not self.use_conv:\n",
    "            w = w.view(x.size(0), -1)\n",
    "        w = self.conv1(w) if self.use_conv else self.fc1(w)\n",
    "        w = self.activ(w)\n",
    "        w = self.conv2(w) if self.use_conv else self.fc2(w)\n",
    "        w = self.sigmoid(w)\n",
    "        if not self.use_conv:\n",
    "            w = w.unsqueeze(2).unsqueeze(3)\n",
    "        x = x * w\n",
    "        return x\n",
    "\n",
    "\n",
    "class SABlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Split-Attention block from 'ResNeSt: Split-Attention Networks,' https://arxiv.org/abs/2004.08955.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    groups : int\n",
    "        Number of channel groups (cardinality, without radix).\n",
    "    radix : int\n",
    "        Number of splits within a cardinal group.\n",
    "    reduction : int, default 4\n",
    "        Squeeze reduction value.\n",
    "    min_channels : int, default 32\n",
    "        Minimal number of squeezed channels.\n",
    "    use_conv : bool, default True\n",
    "        Whether to convolutional layers instead of fully-connected ones.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 out_channels,\n",
    "                 groups,\n",
    "                 radix,\n",
    "                 reduction=4,\n",
    "                 min_channels=32,\n",
    "                 use_conv=True,\n",
    "                 bn_eps=1e-5):\n",
    "        super(SABlock, self).__init__()\n",
    "        self.groups = groups\n",
    "        self.radix = radix\n",
    "        self.use_conv = use_conv\n",
    "        in_channels = out_channels * radix\n",
    "        mid_channels = max(in_channels // reduction, min_channels)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        if use_conv:\n",
    "            self.conv1 = conv1x1(\n",
    "                in_channels=out_channels,\n",
    "                out_channels=mid_channels,\n",
    "                bias=True)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(\n",
    "                in_features=out_channels,\n",
    "                out_features=mid_channels)\n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            num_features=mid_channels,\n",
    "            eps=bn_eps)\n",
    "        self.activ = nn.ReLU(inplace=True)\n",
    "        if use_conv:\n",
    "            self.conv2 = conv1x1(\n",
    "                in_channels=mid_channels,\n",
    "                out_channels=in_channels,\n",
    "                bias=True)\n",
    "        else:\n",
    "            self.fc2 = nn.Linear(\n",
    "                in_features=mid_channels,\n",
    "                out_features=in_channels)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, height, width = x.size()\n",
    "        x = x.view(batch, self.radix, channels // self.radix, height, width)\n",
    "        w = x.sum(dim=1)\n",
    "        w = self.pool(w)\n",
    "        if not self.use_conv:\n",
    "            w = w.view(x.size(0), -1)\n",
    "        w = self.conv1(w) if self.use_conv else self.fc1(w)\n",
    "        w = self.bn(w)\n",
    "        w = self.activ(w)\n",
    "        w = self.conv2(w) if self.use_conv else self.fc2(w)\n",
    "        w = w.view(batch, self.groups, self.radix, -1)\n",
    "        w = torch.transpose(w, 1, 2).contiguous()\n",
    "        w = self.softmax(w)\n",
    "        w = w.view(batch, self.radix, -1, 1, 1)\n",
    "        x = x * w\n",
    "        x = x.sum(dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SAConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Split-Attention convolution block from 'ResNeSt: Split-Attention Networks,' https://arxiv.org/abs/2004.08955.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    kernel_size : int or tuple/list of 2 int\n",
    "        Convolution window size.\n",
    "    stride : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    padding : int, or tuple/list of 2 int, or tuple/list of 4 int\n",
    "        Padding value for convolution layer.\n",
    "    dilation : int or tuple/list of 2 int, default 1\n",
    "        Dilation value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    use_bn : bool, default True\n",
    "        Whether to use BatchNorm layer.\n",
    "    bn_eps : float, default 1e-5\n",
    "        Small float added to variance in Batch norm.\n",
    "    activation : function or str or None, default nn.ReLU(inplace=True)\n",
    "        Activation function or name of activation function.\n",
    "    radix : int, default 2\n",
    "        Number of splits within a cardinal group.\n",
    "    reduction : int, default 4\n",
    "        Squeeze reduction value.\n",
    "    min_channels : int, default 32\n",
    "        Minimal number of squeezed channels.\n",
    "    use_conv : bool, default True\n",
    "        Whether to convolutional layers instead of fully-connected ones.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=False,\n",
    "                 use_bn=True,\n",
    "                 bn_eps=1e-5,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True)),\n",
    "                 radix=2,\n",
    "                 reduction=4,\n",
    "                 min_channels=32,\n",
    "                 use_conv=True):\n",
    "        super(SAConvBlock, self).__init__()\n",
    "        self.conv = ConvBlock(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=(out_channels * radix),\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=(groups * radix),\n",
    "            bias=bias,\n",
    "            use_bn=use_bn,\n",
    "            bn_eps=bn_eps,\n",
    "            activation=activation)\n",
    "        self.att = SABlock(\n",
    "            out_channels=out_channels,\n",
    "            groups=groups,\n",
    "            radix=radix,\n",
    "            reduction=reduction,\n",
    "            min_channels=min_channels,\n",
    "            use_conv=use_conv,\n",
    "            bn_eps=bn_eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.att(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def saconv3x3_block(in_channels,\n",
    "                    out_channels,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    **kwargs):\n",
    "    \"\"\"\n",
    "    3x3 version of the Split-Attention convolution block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    \"\"\"\n",
    "    return SAConvBlock(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        **kwargs)\n",
    "\n",
    "\n",
    "class DucBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Dense Upsampling Convolution (DUC) block from 'Understanding Convolution for Semantic Segmentation,'\n",
    "    https://arxiv.org/abs/1702.08502.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    scale_factor : int\n",
    "        Multiplier for spatial size.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 scale_factor):\n",
    "        super(DucBlock, self).__init__()\n",
    "        mid_channels = (scale_factor * scale_factor) * out_channels\n",
    "\n",
    "        self.conv = conv3x3_block(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=mid_channels)\n",
    "        self.pix_shuffle = nn.PixelShuffle(upscale_factor=scale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pix_shuffle(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class IBN(nn.Module):\n",
    "    \"\"\"\n",
    "    Instance-Batch Normalization block from 'Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net,'\n",
    "    https://arxiv.org/abs/1807.09441.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of channels.\n",
    "    inst_fraction : float, default 0.5\n",
    "        The first fraction of channels for normalization.\n",
    "    inst_first : bool, default True\n",
    "        Whether instance normalization be on the first part of channels.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 first_fraction=0.5,\n",
    "                 inst_first=True):\n",
    "        super(IBN, self).__init__()\n",
    "        self.inst_first = inst_first\n",
    "        h1_channels = int(math.floor(channels * first_fraction))\n",
    "        h2_channels = channels - h1_channels\n",
    "        self.split_sections = [h1_channels, h2_channels]\n",
    "\n",
    "        if self.inst_first:\n",
    "            self.inst_norm = nn.InstanceNorm2d(\n",
    "                num_features=h1_channels,\n",
    "                affine=True)\n",
    "            self.batch_norm = nn.BatchNorm2d(num_features=h2_channels)\n",
    "        else:\n",
    "            self.batch_norm = nn.BatchNorm2d(num_features=h1_channels)\n",
    "            self.inst_norm = nn.InstanceNorm2d(\n",
    "                num_features=h2_channels,\n",
    "                affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = torch.split(x, split_size_or_sections=self.split_sections, dim=1)\n",
    "        if self.inst_first:\n",
    "            x1 = self.inst_norm(x1.contiguous())\n",
    "            x2 = self.batch_norm(x2.contiguous())\n",
    "        else:\n",
    "            x1 = self.batch_norm(x1.contiguous())\n",
    "            x2 = self.inst_norm(x2.contiguous())\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DualPathSequential(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A sequential container for modules with dual inputs/outputs.\n",
    "    Modules will be executed in the order they are added.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    return_two : bool, default True\n",
    "        Whether to return two output after execution.\n",
    "    first_ordinals : int, default 0\n",
    "        Number of the first modules with single input/output.\n",
    "    last_ordinals : int, default 0\n",
    "        Number of the final modules with single input/output.\n",
    "    dual_path_scheme : function\n",
    "        Scheme of dual path response for a module.\n",
    "    dual_path_scheme_ordinal : function\n",
    "        Scheme of dual path response for an ordinal module.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 return_two=True,\n",
    "                 first_ordinals=0,\n",
    "                 last_ordinals=0,\n",
    "                 dual_path_scheme=(lambda module, x1, x2: module(x1, x2)),\n",
    "                 dual_path_scheme_ordinal=(lambda module, x1, x2: (module(x1), x2))):\n",
    "        super(DualPathSequential, self).__init__()\n",
    "        self.return_two = return_two\n",
    "        self.first_ordinals = first_ordinals\n",
    "        self.last_ordinals = last_ordinals\n",
    "        self.dual_path_scheme = dual_path_scheme\n",
    "        self.dual_path_scheme_ordinal = dual_path_scheme_ordinal\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "        length = len(self._modules.values())\n",
    "        for i, module in enumerate(self._modules.values()):\n",
    "            if (i < self.first_ordinals) or (i >= length - self.last_ordinals):\n",
    "                x1, x2 = self.dual_path_scheme_ordinal(module, x1, x2)\n",
    "            else:\n",
    "                x1, x2 = self.dual_path_scheme(module, x1, x2)\n",
    "        if self.return_two:\n",
    "            return x1, x2\n",
    "        else:\n",
    "            return x1\n",
    "\n",
    "\n",
    "class Concurrent(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A container for concatenation of modules on the base of the sequential container.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    axis : int, default 1\n",
    "        The axis on which to concatenate the outputs.\n",
    "    stack : bool, default False\n",
    "        Whether to concatenate tensors along a new dimension.\n",
    "    merge_type : str, default None\n",
    "        Type of branch merging.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 axis=1,\n",
    "                 stack=False,\n",
    "                 merge_type=None):\n",
    "        super(Concurrent, self).__init__()\n",
    "        assert (merge_type is None) or (merge_type in [\"cat\", \"stack\", \"sum\"])\n",
    "        self.axis = axis\n",
    "        if merge_type is not None:\n",
    "            self.merge_type = merge_type\n",
    "        else:\n",
    "            self.merge_type = \"stack\" if stack else \"cat\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        for module in self._modules.values():\n",
    "            out.append(module(x))\n",
    "        if self.merge_type == \"stack\":\n",
    "            out = torch.stack(tuple(out), dim=self.axis)\n",
    "        elif self.merge_type == \"cat\":\n",
    "            out = torch.cat(tuple(out), dim=self.axis)\n",
    "        elif self.merge_type == \"sum\":\n",
    "            out = torch.stack(tuple(out), dim=self.axis).sum(self.axis)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        return out\n",
    "\n",
    "\n",
    "class SequentialConcurrent(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A sequential container with concatenated outputs.\n",
    "    Modules will be executed in the order they are added.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    axis : int, default 1\n",
    "        The axis on which to concatenate the outputs.\n",
    "    stack : bool, default False\n",
    "        Whether to concatenate tensors along a new dimension.\n",
    "    cat_input : bool, default True\n",
    "        Whether to concatenate input tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 axis=1,\n",
    "                 stack=False,\n",
    "                 cat_input=True):\n",
    "        super(SequentialConcurrent, self).__init__()\n",
    "        self.axis = axis\n",
    "        self.stack = stack\n",
    "        self.cat_input = cat_input\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [x] if self.cat_input else []\n",
    "        for module in self._modules.values():\n",
    "            x = module(x)\n",
    "            out.append(x)\n",
    "        if self.stack:\n",
    "            out = torch.stack(tuple(out), dim=self.axis)\n",
    "        else:\n",
    "            out = torch.cat(tuple(out), dim=self.axis)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ParametricSequential(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A sequential container for modules with parameters.\n",
    "    Modules will be executed in the order they are added.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        super(ParametricSequential, self).__init__(*args)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, **kwargs)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ParametricConcurrent(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A container for concatenation of modules with parameters.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    axis : int, default 1\n",
    "        The axis on which to concatenate the outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, axis=1):\n",
    "        super(ParametricConcurrent, self).__init__()\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        out = []\n",
    "        for module in self._modules.values():\n",
    "            out.append(module(x, **kwargs))\n",
    "        out = torch.cat(tuple(out), dim=self.axis)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Hourglass(nn.Module):\n",
    "    \"\"\"\n",
    "    A hourglass module.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    down_seq : nn.Sequential\n",
    "        Down modules as sequential.\n",
    "    up_seq : nn.Sequential\n",
    "        Up modules as sequential.\n",
    "    skip_seq : nn.Sequential\n",
    "        Skip connection modules as sequential.\n",
    "    merge_type : str, default 'add'\n",
    "        Type of concatenation of up and skip outputs.\n",
    "    return_first_skip : bool, default False\n",
    "        Whether return the first skip connection output. Used in ResAttNet.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 down_seq,\n",
    "                 up_seq,\n",
    "                 skip_seq,\n",
    "                 merge_type=\"add\",\n",
    "                 return_first_skip=False):\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.depth = len(down_seq)\n",
    "        assert (merge_type in [\"cat\", \"add\"])\n",
    "        assert (len(up_seq) == self.depth)\n",
    "        assert (len(skip_seq) in (self.depth, self.depth + 1))\n",
    "        self.merge_type = merge_type\n",
    "        self.return_first_skip = return_first_skip\n",
    "        self.extra_skip = (len(skip_seq) == self.depth + 1)\n",
    "\n",
    "        self.down_seq = down_seq\n",
    "        self.up_seq = up_seq\n",
    "        self.skip_seq = skip_seq\n",
    "\n",
    "    def _merge(self, x, y):\n",
    "        if y is not None:\n",
    "            if self.merge_type == \"cat\":\n",
    "                x = torch.cat((x, y), dim=1)\n",
    "            elif self.merge_type == \"add\":\n",
    "                x = x + y\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        y = None\n",
    "        down_outs = [x]\n",
    "        for down_module in self.down_seq._modules.values():\n",
    "            x = down_module(x)\n",
    "            down_outs.append(x)\n",
    "        for i in range(len(down_outs)):\n",
    "            if i != 0:\n",
    "                y = down_outs[self.depth - i]\n",
    "                skip_module = self.skip_seq[self.depth - i]\n",
    "                y = skip_module(y)\n",
    "                x = self._merge(x, y)\n",
    "            if i != len(down_outs) - 1:\n",
    "                if (i == 0) and self.extra_skip:\n",
    "                    skip_module = self.skip_seq[self.depth]\n",
    "                    x = skip_module(x)\n",
    "                up_module = self.up_seq[self.depth - 1 - i]\n",
    "                x = up_module(x)\n",
    "        if self.return_first_skip:\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class SesquialteralHourglass(nn.Module):\n",
    "    \"\"\"\n",
    "    A sesquialteral hourglass block.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    down1_seq : nn.Sequential\n",
    "        The first down modules as sequential.\n",
    "    skip1_seq : nn.Sequential\n",
    "        The first skip connection modules as sequential.\n",
    "    up_seq : nn.Sequential\n",
    "        Up modules as sequential.\n",
    "    skip2_seq : nn.Sequential\n",
    "        The second skip connection modules as sequential.\n",
    "    down2_seq : nn.Sequential\n",
    "        The second down modules as sequential.\n",
    "    merge_type : str, default 'cat'\n",
    "        Type of concatenation of up and skip outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 down1_seq,\n",
    "                 skip1_seq,\n",
    "                 up_seq,\n",
    "                 skip2_seq,\n",
    "                 down2_seq,\n",
    "                 merge_type=\"cat\"):\n",
    "        super(SesquialteralHourglass, self).__init__()\n",
    "        assert (len(down1_seq) == len(up_seq))\n",
    "        assert (len(down1_seq) == len(down2_seq))\n",
    "        assert (len(skip1_seq) == len(skip2_seq))\n",
    "        assert (len(down1_seq) == len(skip1_seq) - 1)\n",
    "        assert (merge_type in [\"cat\", \"add\"])\n",
    "        self.merge_type = merge_type\n",
    "        self.depth = len(down1_seq)\n",
    "\n",
    "        self.down1_seq = down1_seq\n",
    "        self.skip1_seq = skip1_seq\n",
    "        self.up_seq = up_seq\n",
    "        self.skip2_seq = skip2_seq\n",
    "        self.down2_seq = down2_seq\n",
    "\n",
    "    def _merge(self, x, y):\n",
    "        if y is not None:\n",
    "            if self.merge_type == \"cat\":\n",
    "                x = torch.cat((x, y), dim=1)\n",
    "            elif self.merge_type == \"add\":\n",
    "                x = x + y\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        y = self.skip1_seq[0](x)\n",
    "        skip1_outs = [y]\n",
    "        for i in range(self.depth):\n",
    "            x = self.down1_seq[i](x)\n",
    "            y = self.skip1_seq[i + 1](x)\n",
    "            skip1_outs.append(y)\n",
    "        x = skip1_outs[self.depth]\n",
    "        y = self.skip2_seq[0](x)\n",
    "        skip2_outs = [y]\n",
    "        for i in range(self.depth):\n",
    "            x = self.up_seq[i](x)\n",
    "            y = skip1_outs[self.depth - 1 - i]\n",
    "            x = self._merge(x, y)\n",
    "            y = self.skip2_seq[i + 1](x)\n",
    "            skip2_outs.append(y)\n",
    "        x = self.skip2_seq[self.depth](x)\n",
    "        for i in range(self.depth):\n",
    "            x = self.down2_seq[i](x)\n",
    "            y = skip2_outs[self.depth - 1 - i]\n",
    "            x = self._merge(x, y)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiOutputSequential(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A sequential container with multiple outputs.\n",
    "    Modules will be executed in the order they are added.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    multi_output : bool, default True\n",
    "        Whether to return multiple output.\n",
    "    dual_output : bool, default False\n",
    "        Whether to return dual output.\n",
    "    return_last : bool, default True\n",
    "        Whether to forcibly return last value.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 multi_output=True,\n",
    "                 dual_output=False,\n",
    "                 return_last=True):\n",
    "        super(MultiOutputSequential, self).__init__()\n",
    "        self.multi_output = multi_output\n",
    "        self.dual_output = dual_output\n",
    "        self.return_last = return_last\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for module in self._modules.values():\n",
    "            x = module(x)\n",
    "            if hasattr(module, \"do_output\") and module.do_output:\n",
    "                outs.append(x)\n",
    "            elif hasattr(module, \"do_output2\") and module.do_output2:\n",
    "                assert (type(x) == tuple)\n",
    "                outs.extend(x[1])\n",
    "                x = x[0]\n",
    "        if self.multi_output:\n",
    "            return [x] + outs if self.return_last else outs\n",
    "        elif self.dual_output:\n",
    "            return x, outs\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class ParallelConcurent(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A sequential container with multiple inputs and single/multiple outputs.\n",
    "    Modules will be executed in the order they are added.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    axis : int, default 1\n",
    "        The axis on which to concatenate the outputs.\n",
    "    merge_type : str, default 'list'\n",
    "        Type of branch merging.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 axis=1,\n",
    "                 merge_type=\"list\"):\n",
    "        super(ParallelConcurent, self).__init__()\n",
    "        assert (merge_type is None) or (merge_type in [\"list\", \"cat\", \"stack\", \"sum\"])\n",
    "        self.axis = axis\n",
    "        self.merge_type = merge_type\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        for module, xi in zip(self._modules.values(), x):\n",
    "            out.append(module(xi))\n",
    "        if self.merge_type == \"list\":\n",
    "            pass\n",
    "        elif self.merge_type == \"stack\":\n",
    "            out = torch.stack(tuple(out), dim=self.axis)\n",
    "        elif self.merge_type == \"cat\":\n",
    "            out = torch.cat(tuple(out), dim=self.axis)\n",
    "        elif self.merge_type == \"sum\":\n",
    "            out = torch.stack(tuple(out), dim=self.axis).sum(self.axis)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        return out\n",
    "\n",
    "\n",
    "class DualPathParallelConcurent(nn.Sequential):\n",
    "    \"\"\"\n",
    "    A sequential container with multiple dual-path inputs and single/multiple outputs.\n",
    "    Modules will be executed in the order they are added.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    axis : int, default 1\n",
    "        The axis on which to concatenate the outputs.\n",
    "    merge_type : str, default 'list'\n",
    "        Type of branch merging.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 axis=1,\n",
    "                 merge_type=\"list\"):\n",
    "        super(DualPathParallelConcurent, self).__init__()\n",
    "        assert (merge_type is None) or (merge_type in [\"list\", \"cat\", \"stack\", \"sum\"])\n",
    "        self.axis = axis\n",
    "        self.merge_type = merge_type\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1_out = []\n",
    "        x2_out = []\n",
    "        for module, x1i, x2i in zip(self._modules.values(), x1, x2):\n",
    "            y1i, y2i = module(x1i, x2i)\n",
    "            x1_out.append(y1i)\n",
    "            x2_out.append(y2i)\n",
    "        if self.merge_type == \"list\":\n",
    "            pass\n",
    "        elif self.merge_type == \"stack\":\n",
    "            x1_out = torch.stack(tuple(x1_out), dim=self.axis)\n",
    "            x2_out = torch.stack(tuple(x2_out), dim=self.axis)\n",
    "        elif self.merge_type == \"cat\":\n",
    "            x1_out = torch.cat(tuple(x1_out), dim=self.axis)\n",
    "            x2_out = torch.cat(tuple(x2_out), dim=self.axis)\n",
    "        elif self.merge_type == \"sum\":\n",
    "            x1_out = torch.stack(tuple(x1_out), dim=self.axis).sum(self.axis)\n",
    "            x2_out = torch.stack(tuple(x2_out), dim=self.axis).sum(self.axis)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        return x1_out, x2_out\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple flatten module.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class HeatmapMaxDetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Heatmap maximum detector block (for human pose estimation task).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HeatmapMaxDetBlock, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        heatmap = x\n",
    "        vector_dim = 2\n",
    "        batch = heatmap.shape[0]\n",
    "        channels = heatmap.shape[1]\n",
    "        in_size = x.shape[2:]\n",
    "        heatmap_vector = heatmap.view(batch, channels, -1)\n",
    "        scores, indices = heatmap_vector.max(dim=vector_dim, keepdims=True)\n",
    "        scores_mask = (scores > 0.0).float()\n",
    "        pts_x = (indices % in_size[1]) * scores_mask\n",
    "        pts_y = (indices // in_size[1]) * scores_mask\n",
    "        pts = torch.cat((pts_x, pts_y, scores), dim=vector_dim)\n",
    "        for b in range(batch):\n",
    "            for k in range(channels):\n",
    "                hm = heatmap[b, k, :, :]\n",
    "                px = int(pts[b, k, 0])\n",
    "                py = int(pts[b, k, 1])\n",
    "                if (0 < px < in_size[1] - 1) and (0 < py < in_size[0] - 1):\n",
    "                    pts[b, k, 0] += (hm[py, px + 1] - hm[py, px - 1]).sign() * 0.25\n",
    "                    pts[b, k, 1] += (hm[py + 1, px] - hm[py - 1, px]).sign() * 0.25\n",
    "        return pts\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_flops(x):\n",
    "        assert (x.shape[0] == 1)\n",
    "        num_flops = x.numel() + 26 * x.shape[1]\n",
    "        num_macs = 0\n",
    "        return num_flops, num_macs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a183778-f349-445d-94db-f5607d09ea0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
